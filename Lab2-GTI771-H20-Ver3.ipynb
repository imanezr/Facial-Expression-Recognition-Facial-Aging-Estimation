{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab2-GTI771-H20-Ver3.ipynb","provenance":[],"collapsed_sections":["VmkpEUNYKOfX","8Czqr-LxKOg_"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ppeXMqymKOfO"},"source":["### Partie (1c): Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oUnOtzR6KOfR"},"source":["# Laboratoire 2\n","# Discrimination linéaire et réseaux de neurones profonds\n","## Classification et régression (FER et FG-NET)\n","\n","### GTI771 - Apprentissage machine avancé\n","#### Département du génie logiciel et des technologies de l’information\n","\n","#### Version 1.0 février 2020\n","#### <font color=blue> Version 2.0 - 17 février 2020 </font>\n","#### <font color=magenta> Version 3.0 - 2 mars 2020 </font>\n","\n","##### Prof. Alessandro L. Koerich"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wtPvTl3gKOfV"},"source":["| Étudiants             | Branavan Inthiranathan INTB25099502                                 |\n","|-----------------------|---------------------------------------------------------|\n","| Session               | HIV 2020                                            |\n","| Équipe                | 10                                                       |\n","| Numéro du laboratoire | 1                                                       |\n","| Professeur            | Prof. Alessandro L.Koerich                                               |\n","| Chargé de laboratoire | Alessandro L.Koerich                                                     |\n","| Date                  | 15 MARS 2020                                                    |"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VmkpEUNYKOfX"},"source":["## Introduction\n","\n","Ce deuxième laboratoire porte sur l'utilisation de trois algorithmes d'apprentissage soit les algorithmes de régression, les réseaux neuronaux et les réseaux neuronaux profonds. Dans ce laboratoire, vous êtes amenés à utiliser de nouvelles approches à l’aide de ces algorithmes aﬁn de résoudre deux problèmes: prédiction de l'âge de personnes à partir de photos du visage (régression); problème de classiﬁcation des expressions faciales (FER) introduit dans le cadre du premier laboratoire de ce cours.\n","\n","Le problème de régression qui vous est présenté est le problème [Facial Aging Estimation (FAE)](https://yanweifu.github.io/FG_NET_data/index.html), dont le but est de predire l'âge des personnes à partir du visage. En vous basant sur les concepts vus en classe et l'expérience acquise dans le laboratoire 1, vous êtes invité à reprendre les primitives développées lors du laboratoire 1 ou d'autres primitives que vous jugez pertinentes à extraire sur ces types d’images et effectuer l’extraction de celles-ci sur l’ensemble de données fournies avec cet énoncé. \n","\n","##### Description de l'ensemble de données:\n","* 1002 images faciales de 82 sujets multiraciaux âgés de 0 à 69 ans;\n","* Déséquilibré: 50% des sujets ont entre 0 et 13 ans;\n","* Images couleur et niveaux de gris avec une dimension moyenne de 384x487 pixels, et la résolution varie de 200 dpi à 1200 dpi;\n","* Grande variation d'éclairage, de pose, d'expression faciale, de flou et d'occlusions (par exemple, moustache, barbe, lunettes, etc.).\n","\n","Voici, en exemple, des images de visages se retrouvant dans l’ensemble de données FG-NET:\n","\n","![Exemples de FER](https://www.mdpi.com/sensors/sensors-16-00994/article_deploy/html/images/sensors-16-00994-g001.png)\n","\n","Veuillez noter que les images qui vous sont fournies ne sont pas nécessairement similaires aux images de FER. Plusieurs images comportent du bruit, des artéfacts ou des éléments non pertinents. Le défi de ce laboratoire repose sur cette difficulté qui est chose courante dans des problèmes d’apprentissage machine moderne.\n","\n","Tout comme le premier travail pratique, vous réaliserez ce deuxième laboratoire avec la technologie Python3 conjointement avec la librairie d’apprentissage machine scikit-learn et TensorFlow et Keras pour la partie réseaux de neurones. Vous êtes invité à reprendre le code développé lors du laboratoire 1 afin de continuer son développement.\n","\n","<font color=black> L’évaluation de ce laboratoire sera basée sur la qualité des modèles entraînes, la comparaison des performances réalisées par les différents modèles, les réponses aux questions dans cette notebook ainsi que l'organisation de votre code source (SVP, n'oubliez pas des commentaires dans le code!).</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qB7iVH1vKOfa"},"source":["* #### Partie 1: Régression\n","* Régression lineaire\n","* Régression Ridge\n","* Régression Lasso et Elastic-Net\n","* Descente du gradiente stochastique (SGD)\n","* Perceptron ??\n","* Primitives polynomiales et régression polynomiale ?? <br>\n","<br>\n","* #### Partie 2: Classification\n","* Régression logistique\n","* Réseaux de neurones MLP <br>\n","<br>\n","* #### Partie 3: Classification et régression\n","* Réseaux convolutionel entraîné \"from scratch\"\n","* Réseaux convolutionel + modèles pre-entraînes (transfer learning)\n","* Réseaux convolutionel adapté à la régression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"tVnr7zLmKOff"},"source":["## Partie 0: Imports"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NSfcu7YLKOfh"},"source":["#### (1a) Import de bibliotèques\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QkKxge1BKOfk"},"source":["##### À faire:\n","1. Ajouter toutes les bibliothèques que vous avez utilisées pour compléter ce notebook dans une cellule avec une petite description."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OGh7rkMBien_","colab":{}},"source":["import numpy\n","import pylab\n","import numpy as np  # package for scientific computing with Python.\n","import matplotlib.pyplot as plt # 2D plotting library\n","from sklearn.preprocessing import MinMaxScaler #Normalisation\n","from sklearn.model_selection import LeaveOneGroupOut #Define the LOSO\n","from sklearn.linear_model import LinearRegression #Regression lineaire\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from sklearn.linear_model import Ridge #Regression Ridge\n","from sklearn.linear_model import Lasso #Regression Lasso\n","from sklearn.linear_model import ElasticNet #Regression ElasticNet\n","\n","from sklearn.linear_model import LogisticRegression #2b regression logistique\n","from sklearn.metrics import accuracy_score\n","from keras.utils import np_utils #2c keras np_utils\n","\n","# Votre code ici"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"baIjs7j6KOft"},"source":["## Partie 1: Explorez les algorithmes de régression (FG-NET dataset)\n","\n","Dans ce partie vous devez explorer le <b> algorithmes de régression lineaire </b> disponibles dans Scikit-learn, comme régression least square, régression Ridge, régression Lasso et Elastic-Net, descente du gradiente stochastique (SGD), etc.\n","\n","Vouz devez comparer la performance de ces algorithmes pour l'ensemble FG-NET sur:\n","\n","#### 1) Le vecteur de pixels (images vectorisés)\n","#### 2) Vecteur de primitives (reprendre les primitives du lab 1)\n","#### 3) Vecteur de primitives selectionés/transformés (reprendre les primitives du lab 1)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8HVNR1HaKOfv"},"source":["### (1a) Charger le fichier de données"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6wR2RKzHieoN","colab":{}},"source":["# Load data\n","X_fgnet_48 = np.loadtxt('fgnet_48x48.csv', delimiter=',', dtype=int)\n","X_fgnet_256 = np.loadtxt('fgnet_256x256.csv', delimiter=',', dtype=int)\n","Y_fgnet_subject = np.loadtxt('fgnet_subjects.csv', delimiter=',', dtype=int) #Le numero du sujet\n","Y_fgnet_age = np.loadtxt('fgnet_labels.csv', delimiter=',', dtype=int) #label de l'ag\n","\n","\n","#mis en commentaire pour essayer l'exemple du prof\n","#X_fgnet_48 = X_fgnet_48.reshape(X_fgnet_48.shape[0],1,48,48).astype('uint8')\n","#X_fgnet_256  = X_fgnet_256.reshape(X_fgnet_256.shape[0], 1, 256, 256).astype('uint8')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xLTz_h2wKOf5"},"source":["### <font color=black> (1b) Visualisation des visages </font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HFb5APCxKOf7"},"source":["Pensez-vous qui c'est necessaire un pre-traitement des images? Si oui, \n","[Pre-processing](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n","\n","\n","Voici deux sources pour vous aidez à décider:\n","- http://eprints.qut.edu.au/92300/1/manuscript_Jhony.pdf\n","- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7475805"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T6fYZKneieoR","colab":{}},"source":["# Normalize the input data\n","scaler = MinMaxScaler()\n","scaler.fit(X_fgnet_48)\n","X_fgnet_48 = scaler.transform(X_fgnet_48)\n","scaler.fit(X_fgnet_256)\n","X_fgnet_256 = scaler.transform(X_fgnet_256)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pVWaUY_lKOf9"},"source":["### (1c) Statistiques sur les sujets et étiquettes"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PwPudHu7KOf-"},"source":["##### À faire:\n","1. Calculer quelques statistiques (# images par sujet, distribuition des âges, etc.) que vous jugez importantes sur les données\n","2. Faire une analyse des résultats et présenter vos conclusions basés sur ces statistiques."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vmTlosHNKOgA"},"source":["### Partie (1c): Code:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cNw7pnqYieob","colab":{}},"source":["def getListNbImageBySubject():\n","    listNbImage= [0] * (np.amax(Y_fgnet_subject)+1)\n","    for subject in Y_fgnet_subject:\n","        listNbImage[subject]+=1\n","    return listNbImage\n","\n","def getListAgeByImage():\n","    listAge = [0] * (np.amax(Y_fgnet_age)+1)\n","    for age in Y_fgnet_age:\n","        listAge[age]+=1\n","    return listAge\n","    # Code exemple:\n","# Histogramme des étiquettes\n","#hist, _ = np.histogram(ytrain, density=False, bins=7, range=(0, 7))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nmRi07m5KOgL"},"source":["### Partie (1c): Résultats et résponses:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rPDRLNQ9ieoh","outputId":"e460d027-5788-46fd-e0e2-ccc80e4da687","executionInfo":{"status":"ok","timestamp":1584312030151,"user_tz":240,"elapsed":358,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["print(\"Nombre d'image par sujet\")\n","listNbImage = getListNbImageBySubject()\n","print(listNbImage)\n","print(\"Moyenne d'image pour un sujet \" + str(np.mean(listNbImage)))\n","print(\"L'écart-type d'image pour un sujet \" + str(np.std(listNbImage)))\n","\n","print(\"Distribution des images par l'âge\")\n","listAge = getListAgeByImage()\n","print(listAge)\n","print(\"Moyenne d'image pour l'âge \" + str(np.mean(listAge)))\n","print(\"Médiane d'image de l'âge \" + str(np.median(listAge)))\n","print(\"Écart-type d'image pour l'âge \" + str(np.std(listAge)))\n","# Plot du histogramme\n","\n","#import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Nombre d'image par sujet\n","[0, 15, 16, 12, 12, 11, 12, 9, 15, 13, 12, 14, 15, 12, 10, 13, 13, 13, 11, 10, 13, 12, 13, 12, 11, 12, 11, 11, 11, 13, 11, 13, 12, 11, 13, 14, 13, 12, 14, 14, 14, 10, 13, 11, 10, 13, 13, 14, 16, 10, 8, 11, 11, 13, 13, 8, 8, 10, 11, 9, 12, 13, 12, 10, 6, 15, 12, 10, 10, 11, 11, 13, 14, 16, 16, 10, 18, 16, 16, 14, 14, 12, 11]\n","Moyenne d'image pour un sujet 12.072289156626505\n","L'écart-type d'image pour un sujet 2.5067769953348966\n","Distribution des images par l'âge\n","[43, 27, 39, 42, 42, 40, 41, 41, 31, 25, 40, 33, 37, 32, 32, 30, 37, 28, 47, 23, 20, 16, 17, 22, 9, 17, 11, 11, 12, 9, 19, 6, 4, 9, 8, 11, 8, 3, 5, 6, 9, 6, 5, 4, 4, 7, 3, 2, 3, 3, 2, 3, 3, 2, 2, 2, 0, 0, 1, 0, 1, 3, 1, 1, 0, 0, 0, 1, 0, 1]\n","Moyenne d'image pour l'âge 14.314285714285715\n","Médiane d'image de l'âge 8.0\n","Écart-type d'image pour l'âge 14.69260538710628\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CunV3-WyXPqu","colab_type":"code","outputId":"0cdbf3b8-7c51-4e79-954b-c9f234299f89","executionInfo":{"status":"ok","timestamp":1584315961584,"user_tz":240,"elapsed":500,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["#Tracer le diagramme à batons \n","Effectifs=listAge\n","fig = plt.figure()\n","x = [i for i in range(70)]\n","width = 0.5\n","plt.bar(x, Effectifs, width, color=(0.65098041296005249, 0.80784314870834351, 0.89019608497619629, 1.0)  )\n","plt.scatter([i for i in x],Effectifs,color='k',s=10)\n","#plt.grid()\n","plt.ylabel('Nbr de personnes par age')\n","plt.xlabel('Age entre 0 et 69 ans')\n","plt.title('Diagramme en Batons ')\n","#pylab.xticks(x,['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'],rotation=40)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n38ysxzjxm5n1mP8DM5KKMd8boG4AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zh2OyxE7KOgS"},"source":["### (1d) Créer et évaluer des modèles de régression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HcCuYRMsKOgV"},"source":["##### À faire:\n","1. Choisir au moins quatre (4) algorithmes de régression lineaire disponibles dans Scikit-learn, comme régression least square, régression Ridge, régression Lasso, régression Elastic-Net, descente du gradiente stochastique (SGD), etc.\n","2. Entraîner et optimiser les paramètres des modèles si necessaire. Utiliser le protocol <font color=blue> \"Leave One Subject Out Cross-Validation\" </font> (LOSO).\n","4. Faire une analyse des résultats et présenter vos conclusions sur les modèles de régression.\n","\n","| Algorithme            | Paramètres                |  MSE  |  MAE  |\n","|-----------------------|---------------------------|-------|-------|\n","| Regr lineaire         | aucun                     |179.22 | 11.56 |\n","| Regr Ridge            | alpha = 100               |44.20  | 6.09  |\n","| Regr Lasso            | alpha = 0.05              | 46.30 | 6.16  |\n","| Regr ElasticNet       | alpha = 0.05, l1_ratio=0.5| 47.35 | 6.26  |\n","\n","Pour chaque modèle de régression créé et évalué dans cette partie, on utilise le protocole LOSO pour faire du cross-validation. L’entrainement pour chaque algorithme est fait avec 82 modèles qui sont le nombre total de sujets dans notre dataset afin d’avoir des datasplits. Le premier modèle de régression est avec LinearRegression, cette régression ajuste le modèle linéaire des coefficients de poids pour minimiser le résidu de la somme des carrés entre cibles observées et prédites, la meansquarederror est 179.22 et la meanabsoluteerror est 11.56 pour faire les prédictions. Le deuxième modèle de régression est avec Ridgeregression, cette régression règle certains problèmes du Ordinary Least Squares en mettant une pénalité sur la grandeur des coefficients avec la régularisation L2, avec un alpha de 100, notre MSE est de 44.20 et la MAE est 6.09. Le troisième modèle de régression est avec Lasso, cette régression estime les coefficients clairsemés avec la régularisation L1 pour résoudre la minimisation des pénalités de leastsquares, en choisissant un alpha de 0.05, notre MSE est de 46.30 et la MAE est 6.16. Le quatrième modèle de régression est avec Elastic-Net, cette régression prend les régularisations L1 et L2 pour les coefficients, avec un alpha de 0.05 et un L1-ratio de 0.5, notre MSE est de 47.35 et la MAE de 6.26. Pour ce qui est de l’utilisation des quatre modèles entrainés, les algorithmes Ridge, Lasso et ElasticNet montre des résultats moins élevés pour les erreurs et sont préférables à l’algorithme de régression linéaire ordinaire."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Js-Xg26PKOgX"},"source":["### Partie (1d): Code:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jDmApjQiieor","outputId":"44b47659-3efc-4d3b-e171-3f97a7d08ea8","executionInfo":{"status":"ok","timestamp":1584308378145,"user_tz":240,"elapsed":66837,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Create n subjects data splits, where n is the total number of subjects in the dataset, \n","# 82 in our case\n","loso = LeaveOneGroupOut()\n","loso.get_n_splits(X_fgnet_48, Y_fgnet_age, Y_fgnet_subject)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["82"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JD8jaGOHieou","colab":{}},"source":["def regressionModel(model_R):\n","  index = 0\n","  acc   = np.zeros( 82 )\n","  for train_index, test_index in loso.split(X_fgnet_48, Y_fgnet_age, Y_fgnet_subject):\n","      X_train, X_test = X_fgnet_48[train_index], X_fgnet_48[test_index]\n","      Y_train, Y_test = Y_fgnet_age[train_index], Y_fgnet_age[test_index]\n","      \n","      # Train the model on X_train, Y_train \n","      model = model_R.fit( X_train, Y_train )\n","      \n","      # Use the learned model to predict on X_test ,Y_test \n","      Y_test_pred      = model.predict( X_test )\n","      \n","      # The coefficients\n","      print('Coefficients: \\n', model.coef_)\n","      # The mean squared error\n","      print('MSE: %.2f' % mean_squared_error(Y_test, Y_test_pred) )\n","      print('MAE: %.2f' % mean_absolute_error(Y_test, Y_test_pred) )\n","          \n","      acc[index] =  mean_absolute_error(Y_test, Y_test_pred)\n","      \n","      index += 1\n","  return acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YB987VrnKOge"},"source":["### Partie (1d): Résultats et résponses:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3SLPax1Uieox","outputId":"82deba8f-5a98-480b-d075-02b2bef68e3e","executionInfo":{"status":"ok","timestamp":1584308452397,"user_tz":240,"elapsed":141073,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["#Regression Lineaire\n","model_LR = LinearRegression()\n","acc = regressionModel(model_LR)\n","print(acc)\n","# Average MAE\n","print(acc.mean())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Coefficients: \n"," [-0.42787108 -3.02072711 -2.61449176 ... -3.62500572  5.82728599\n","  4.75662451]\n","MSE: 528.62\n","MAE: 19.16\n","Coefficients: \n"," [ 0.55800857 -3.19781159 -3.00076643 ... -3.87986929  6.39309079\n","  4.84566778]\n","MSE: 356.13\n","MAE: 14.92\n","Coefficients: \n"," [ 2.21923063 -2.22712859 -1.84897307 ... -4.93009234  6.04806456\n","  6.70403003]\n","MSE: 811.05\n","MAE: 23.73\n","Coefficients: \n"," [ 1.41651267 -4.16581607 -4.30129574 ... -3.6257435   5.57053957\n","  3.79793652]\n","MSE: 1063.63\n","MAE: 26.28\n","Coefficients: \n"," [ 0.24589746 -4.3522487  -2.55039574 ... -3.25843533  7.1218563\n","  5.79529805]\n","MSE: 635.88\n","MAE: 21.79\n","Coefficients: \n"," [-0.05998827 -3.46405901 -2.1636577  ... -4.40841575  7.17757522\n","  6.44934193]\n","MSE: 487.17\n","MAE: 17.48\n","Coefficients: \n"," [ 0.09486351 -4.20631885 -3.11497722 ... -3.4888178   6.87796782\n","  5.95479766]\n","MSE: 232.39\n","MAE: 12.95\n","Coefficients: \n"," [ 1.18747272 -2.58143207 -3.05639517 ... -4.34214889  7.58654163\n","  5.2861925 ]\n","MSE: 208.18\n","MAE: 12.79\n","Coefficients: \n"," [-0.32478503 -1.70461367 -3.14208353 ... -2.34585809  6.25648437\n","  5.60344106]\n","MSE: 617.96\n","MAE: 20.83\n","Coefficients: \n"," [ 0.50211963 -3.91904246 -2.69768277 ... -5.0001124   7.74147157\n","  5.92296128]\n","MSE: 211.81\n","MAE: 12.95\n","Coefficients: \n"," [ 0.52104224 -4.2284779  -4.89788866 ... -3.4534173   9.1377266\n","  5.25516887]\n","MSE: 314.47\n","MAE: 13.85\n","Coefficients: \n"," [ 0.3504742  -2.86426058 -2.87322344 ... -4.91556573  6.80536229\n","  6.70225779]\n","MSE: 271.59\n","MAE: 13.41\n","Coefficients: \n"," [ 0.58922811 -3.249945   -2.711026   ... -3.7137233   7.80693634\n","  5.88236502]\n","MSE: 177.36\n","MAE: 9.06\n","Coefficients: \n"," [ 0.21989269 -3.9827801  -2.84419559 ... -2.80632721  6.92076423\n","  5.65151077]\n","MSE: 598.79\n","MAE: 21.15\n","Coefficients: \n"," [-0.13059146 -4.32665335 -3.82228015 ... -2.95996224  7.90148845\n","  4.29602082]\n","MSE: 250.35\n","MAE: 12.84\n","Coefficients: \n"," [ 0.55633558 -3.61683448 -2.47669422 ... -3.60629809  7.09765942\n","  5.61885355]\n","MSE: 246.46\n","MAE: 13.30\n","Coefficients: \n"," [ 1.70244726 -3.4557788  -4.05435005 ... -4.69885932  6.90925988\n","  6.03544103]\n","MSE: 415.77\n","MAE: 16.64\n","Coefficients: \n"," [ 0.86457459 -3.39022354 -2.6135084  ... -3.28386251  7.34033674\n","  5.91029468]\n","MSE: 296.30\n","MAE: 14.95\n","Coefficients: \n"," [-0.24584528 -4.50995172 -1.83441235 ... -3.62747214  6.42896632\n","  5.62250259]\n","MSE: 253.60\n","MAE: 11.45\n","Coefficients: \n"," [ 0.94229633 -3.4115095  -4.27244613 ... -2.83721039  6.09571736\n","  6.87313161]\n","MSE: 188.97\n","MAE: 11.24\n","Coefficients: \n"," [ 0.97553786 -3.39421387 -2.68344262 ... -4.26555322  6.99901192\n","  6.57625272]\n","MSE: 166.47\n","MAE: 9.58\n","Coefficients: \n"," [ 0.99981837 -3.06444072 -2.50117692 ... -4.42196149  7.52472753\n","  5.23307442]\n","MSE: 147.88\n","MAE: 10.25\n","Coefficients: \n"," [ 0.50728998 -3.70064028 -2.28979233 ... -4.03405226  7.2032979\n","  5.40529959]\n","MSE: 332.07\n","MAE: 14.06\n","Coefficients: \n"," [ 1.49321189 -3.46067682 -2.58983978 ... -4.77485504  7.61739718\n","  5.63329784]\n","MSE: 127.77\n","MAE: 7.92\n","Coefficients: \n"," [ 1.62576668 -2.26676757 -5.17715751 ... -4.42259606  7.46365702\n","  4.81456395]\n","MSE: 369.59\n","MAE: 14.12\n","Coefficients: \n"," [ 1.30312708 -1.0719206  -5.37597311 ... -2.85786039  5.0927468\n","  5.20883798]\n","MSE: 180.42\n","MAE: 12.24\n","Coefficients: \n"," [-0.73183527 -3.87752517 -3.55193625 ... -3.07679901  7.56578678\n","  5.75841294]\n","MSE: 336.90\n","MAE: 15.99\n","Coefficients: \n"," [ 1.19219963 -3.59530383 -3.86225719 ... -2.77281184  7.96892156\n","  3.88523805]\n","MSE: 458.97\n","MAE: 18.45\n","Coefficients: \n"," [ 0.79178795 -3.09341415 -2.58643372 ... -4.78834948  6.86685458\n","  6.44493978]\n","MSE: 120.73\n","MAE: 8.92\n","Coefficients: \n"," [-0.10178914 -2.48410548 -2.31356616 ... -4.1872349   7.54497802\n","  5.58269563]\n","MSE: 356.02\n","MAE: 15.36\n","Coefficients: \n"," [ 0.08466082 -3.95664714 -2.2327196  ... -3.03082928  7.09624894\n","  5.88456134]\n","MSE: 250.25\n","MAE: 12.87\n","Coefficients: \n"," [ 1.66635127 -5.2483015  -3.53103926 ... -4.1793607   6.93560906\n","  6.4227902 ]\n","MSE: 288.49\n","MAE: 11.85\n","Coefficients: \n"," [ 0.79741076 -3.58377061 -2.9884942  ... -4.10753936  6.94970276\n","  5.89999917]\n","MSE: 131.46\n","MAE: 9.08\n","Coefficients: \n"," [ 1.03023588 -1.42058038 -4.27306837 ... -4.09655945  6.28903301\n","  5.4953875 ]\n","MSE: 345.90\n","MAE: 15.40\n","Coefficients: \n"," [ 0.11298764 -3.14535169 -2.48287768 ... -4.42732275  8.11156978\n","  5.5552602 ]\n","MSE: 134.32\n","MAE: 9.80\n","Coefficients: \n"," [ 0.82169746 -3.93856256 -3.53566076 ... -4.549389    7.90421028\n","  5.0915113 ]\n","MSE: 276.69\n","MAE: 14.35\n","Coefficients: \n"," [ 0.04540885 -2.8573026  -3.00716973 ... -5.33047634  5.82415951\n","  6.44464709]\n","MSE: 313.36\n","MAE: 14.48\n","Coefficients: \n"," [ 0.14541108 -2.34597094 -2.89901832 ... -5.0409884   7.05080613\n","  6.9471862 ]\n","MSE: 134.25\n","MAE: 9.10\n","Coefficients: \n"," [-0.36997728 -0.74723221 -3.17465727 ... -2.46209248  5.15677825\n","  5.00620494]\n","MSE: 552.99\n","MAE: 18.69\n","Coefficients: \n"," [ 1.42850415 -2.77337221 -2.79330552 ... -3.41725453  6.36298593\n","  5.99885558]\n","MSE: 335.35\n","MAE: 16.03\n","Coefficients: \n"," [ 1.14044214 -3.35907418 -2.41238823 ... -3.64569727  6.87852066\n","  4.77922956]\n","MSE: 282.40\n","MAE: 12.01\n","Coefficients: \n"," [ 0.35899306 -3.250142   -3.76495854 ... -3.04967728  8.29697171\n","  5.38962507]\n","MSE: 166.46\n","MAE: 10.69\n","Coefficients: \n"," [ 0.69658678 -4.02821847 -3.91562684 ... -3.77358253  7.04108771\n","  6.63951455]\n","MSE: 96.05\n","MAE: 7.73\n","Coefficients: \n"," [ 0.38456982 -3.25245285 -3.2265298  ... -3.76495878  7.00917724\n","  5.25210503]\n","MSE: 64.50\n","MAE: 6.45\n","Coefficients: \n"," [-0.85480407 -3.16667434 -3.75301755 ... -2.08961863  8.52906701\n","  5.34100216]\n","MSE: 437.53\n","MAE: 17.28\n","Coefficients: \n"," [ 0.59312963 -3.14116466 -3.92472673 ... -3.71325841  6.84579348\n","  5.17881649]\n","MSE: 98.08\n","MAE: 8.60\n","Coefficients: \n"," [ 0.82777773 -2.49646261 -2.65811486 ... -4.61716965  7.11133967\n","  6.92564817]\n","MSE: 332.25\n","MAE: 15.44\n","Coefficients: \n"," [ 1.02356088 -4.36137853 -3.20487516 ... -2.11923571  6.85670592\n","  4.46826788]\n","MSE: 408.12\n","MAE: 15.37\n","Coefficients: \n"," [ 1.24941384 -2.77781276 -2.50682605 ... -4.03470121  7.09815821\n","  5.7595691 ]\n","MSE: 196.16\n","MAE: 11.74\n","Coefficients: \n"," [ 0.74853844 -4.18925672 -3.21082385 ... -3.35833108  7.37188949\n","  6.29958615]\n","MSE: 332.33\n","MAE: 14.94\n","Coefficients: \n"," [ 0.52447678 -3.43365879 -3.2953919  ... -4.61279678  6.47827118\n","  6.59504127]\n","MSE: 197.37\n","MAE: 11.89\n","Coefficients: \n"," [ 0.44301416 -3.47897607 -3.3585036  ... -3.54388847  7.12275163\n","  6.3267738 ]\n","MSE: 211.68\n","MAE: 11.12\n","Coefficients: \n"," [ 1.06237111 -3.17309779 -3.6781186  ... -4.00870669  7.05913177\n","  6.67593357]\n","MSE: 210.66\n","MAE: 11.01\n","Coefficients: \n"," [-0.53144334 -3.06829436 -3.62524816 ... -4.5745775   7.5566552\n","  5.42003427]\n","MSE: 177.21\n","MAE: 9.98\n","Coefficients: \n"," [ 1.38524845 -3.20311444 -2.68893641 ... -2.47184065  7.8295781\n","  5.50075436]\n","MSE: 132.76\n","MAE: 8.99\n","Coefficients: \n"," [ 0.80428505 -3.51487525 -3.10027021 ... -3.73621447  7.66066356\n","  5.75931625]\n","MSE: 118.98\n","MAE: 9.15\n","Coefficients: \n"," [ 0.51226533 -3.16789747 -3.3566374  ... -4.05777761  7.28043556\n","  6.40945585]\n","MSE: 228.22\n","MAE: 12.40\n","Coefficients: \n"," [ 0.78790702 -3.05678139 -2.80826883 ... -4.84910018  5.14980216\n","  6.11904178]\n","MSE: 292.66\n","MAE: 14.32\n","Coefficients: \n"," [-0.12307087 -3.11861185 -1.93224311 ... -5.14680773  8.85896524\n","  5.12351298]\n","MSE: 377.48\n","MAE: 15.61\n","Coefficients: \n"," [ 0.42743884 -3.38380044 -3.19351281 ... -3.80773967  6.89468405\n","  5.47539306]\n","MSE: 111.15\n","MAE: 8.28\n","Coefficients: \n"," [ 0.46567802 -3.80503281 -2.62130486 ... -2.95840059  8.08090781\n","  4.38029452]\n","MSE: 273.01\n","MAE: 11.67\n","Coefficients: \n"," [-0.63521275 -2.96103263 -3.1635011  ... -3.18423783  6.11104303\n","  3.96450672]\n","MSE: 499.76\n","MAE: 16.56\n","Coefficients: \n"," [ 0.98851964 -4.36965065 -3.00460337 ... -3.36737023  5.22070268\n","  5.18893308]\n","MSE: 469.13\n","MAE: 16.01\n","Coefficients: \n"," [ 0.46818958 -3.33987728 -3.04703664 ... -4.02831218  7.60593988\n","  5.77929163]\n","MSE: 178.41\n","MAE: 12.89\n","Coefficients: \n"," [ 0.74981968 -3.39597335 -2.59001067 ... -3.80162688  5.90777117\n","  6.38045145]\n","MSE: 307.48\n","MAE: 13.49\n","Coefficients: \n"," [ 1.37209843 -3.8504291  -1.96348434 ... -4.17473617  7.09123111\n","  5.36992719]\n","MSE: 409.09\n","MAE: 16.09\n","Coefficients: \n"," [ 1.07826303 -2.6987583  -3.05630435 ... -4.04541239  7.70636249\n","  7.17146975]\n","MSE: 349.97\n","MAE: 15.28\n","Coefficients: \n"," [ 0.51016516 -3.61202568 -2.31254302 ... -3.97227647  6.85694862\n","  5.91830707]\n","MSE: 223.26\n","MAE: 12.78\n","Coefficients: \n"," [ 0.21165583 -3.99781046 -3.42572759 ... -3.67444021  6.81895751\n","  5.98034257]\n","MSE: 209.44\n","MAE: 11.72\n","Coefficients: \n"," [ 1.72317341 -2.48635554 -1.93068268 ... -2.98516804  7.34108112\n","  5.34494757]\n","MSE: 293.26\n","MAE: 12.89\n","Coefficients: \n"," [ 0.8891847  -3.35199881 -2.9863751  ... -5.45917679  8.05460111\n","  4.88864822]\n","MSE: 283.56\n","MAE: 13.38\n","Coefficients: \n"," [-0.02630721 -3.74526025 -2.64347781 ... -1.75231101  5.41290466\n","  4.7809697 ]\n","MSE: 429.62\n","MAE: 14.87\n","Coefficients: \n"," [ 0.76322289 -3.78013636 -2.46354448 ... -2.89747302  7.47409161\n","  3.9641057 ]\n","MSE: 349.88\n","MAE: 13.67\n","Coefficients: \n"," [ 0.75148066 -3.87994185 -3.81639438 ... -3.9107155   6.71245191\n","  5.79724472]\n","MSE: 229.30\n","MAE: 12.24\n","Coefficients: \n"," [ 1.1148722  -3.05830714 -3.73602295 ... -4.03631344  7.1979051\n","  5.91393128]\n","MSE: 243.65\n","MAE: 13.25\n","Coefficients: \n"," [ 0.73248211 -3.22944969 -4.42500053 ... -3.53443941  7.25728202\n","  4.66192344]\n","MSE: 142.28\n","MAE: 8.64\n","Coefficients: \n"," [ 0.97113113 -4.05015227 -4.18873512 ... -4.81082096  8.03138499\n","  5.63379629]\n","MSE: 250.99\n","MAE: 13.13\n","Coefficients: \n"," [-0.26115571 -3.10655196 -2.25422381 ... -4.12028887  6.17136923\n","  5.72430911]\n","MSE: 262.97\n","MAE: 14.42\n","Coefficients: \n"," [ 0.18382809 -3.57490879 -2.46582887 ... -4.03199833  8.01225476\n","  5.97373077]\n","MSE: 253.49\n","MAE: 13.45\n","Coefficients: \n"," [ 0.12113975 -4.58153619 -2.93600337 ... -4.52909034  6.81469101\n","  5.37141957]\n","MSE: 128.42\n","MAE: 7.94\n","Coefficients: \n"," [ 0.42512453 -3.68724203 -3.77769678 ... -3.40362274  6.76302237\n","  6.28488056]\n","MSE: 430.67\n","MAE: 14.07\n","Coefficients: \n"," [ 0.34227192 -3.06310504 -3.57905921 ... -5.03087758  7.96718698\n","  6.18699196]\n","MSE: 179.23\n","MAE: 11.56\n","[19.16134372 14.91516491 23.73469002 26.27695035 21.79025724 17.48226359\n"," 12.95165461 12.78762401 20.83182855 12.95092434 13.84735142 13.4108607\n","  9.06265092 21.15353853 12.835638   13.30194859 16.63839146 14.95124719\n"," 11.45315227 11.23543676  9.57736258 10.24796568 14.06400817  7.91937444\n"," 14.11861033 12.23528547 15.99456335 18.45322407  8.92392836 15.36143714\n"," 12.86769446 11.85487829  9.07774431 15.39717154  9.80428807 14.34863985\n"," 14.47769142  9.10173227 18.69474568 16.02894819 12.00715532 10.69317457\n","  7.72553089  6.44956052 17.2818223   8.60476343 15.43846487 15.36959797\n"," 11.74087922 14.9437371  11.88637174 11.11791742 11.00731044  9.9824096\n","  8.98784107  9.15223444 12.39957304 14.31897688 15.60827039  8.28378234\n"," 11.66834934 16.56274529 16.00894246 12.89255069 13.48742345 16.09339189\n"," 15.28452294 12.77975974 11.71685896 12.88643416 13.38306262 14.87470365\n"," 13.67083616 12.24230914 13.24606371  8.64202565 13.13259632 14.42144981\n"," 13.44536787  7.94169494 14.07266479 11.5563614 ]\n","13.443069504430934\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ALMJklnfieoz","outputId":"56408cf2-05a2-498d-9bdc-4f6b1de55c17","executionInfo":{"status":"ok","timestamp":1584308464102,"user_tz":240,"elapsed":152772,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model_Ridge = Ridge(alpha = 100)\n","acc = regressionModel(model_Ridge)\n","print(acc)\n","# Average MAE\n","print(acc.mean())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Coefficients: \n"," [-0.34760504 -0.11175615 -0.27744989 ... -0.2970932   0.10225336\n","  0.02503198]\n","MSE: 171.97\n","MAE: 10.95\n","Coefficients: \n"," [-0.31998054 -0.11075963 -0.29117938 ... -0.34720732  0.04683242\n"," -0.01270471]\n","MSE: 77.67\n","MAE: 6.76\n","Coefficients: \n"," [-0.26715492 -0.06562505 -0.28029539 ... -0.34580642  0.03348674\n"," -0.00646022]\n","MSE: 686.77\n","MAE: 21.34\n","Coefficients: \n"," [-0.3193565  -0.11947787 -0.29814905 ... -0.29477062  0.09407227\n","  0.03620316]\n","MSE: 472.61\n","MAE: 16.40\n","Coefficients: \n"," [-0.30836496 -0.1059766  -0.2727272  ... -0.25051836  0.17380303\n","  0.13059322]\n","MSE: 511.56\n","MAE: 18.80\n","Coefficients: \n"," [-0.29923973 -0.144733   -0.27456019 ... -0.39922771  0.05676376\n"," -0.01030247]\n","MSE: 527.72\n","MAE: 18.98\n","Coefficients: \n"," [-0.32542028 -0.09616387 -0.27740512 ... -0.30921584  0.08441777\n","  0.05454971]\n","MSE: 269.89\n","MAE: 14.18\n","Coefficients: \n"," [-0.34385257 -0.12286525 -0.2888083  ... -0.32941587  0.101763\n","  0.04392996]\n","MSE: 114.06\n","MAE: 8.76\n","Coefficients: \n"," [-0.31592292 -0.11811797 -0.29969537 ... -0.31177007  0.08029977\n","  0.01653946]\n","MSE: 41.16\n","MAE: 5.40\n","Coefficients: \n"," [-0.32722728 -0.11144475 -0.29818373 ... -0.33435891  0.08711152\n","  0.0281137 ]\n","MSE: 34.53\n","MAE: 4.97\n","Coefficients: \n"," [-0.25930632 -0.09912146 -0.322247   ... -0.27646693  0.14091879\n","  0.03255359]\n","MSE: 104.15\n","MAE: 7.80\n","Coefficients: \n"," [-0.30606959 -0.0681385  -0.25630863 ... -0.29872211  0.11561498\n","  0.06626438]\n","MSE: 94.38\n","MAE: 8.63\n","Coefficients: \n"," [-0.27106573 -0.12358564 -0.29129339 ... -0.3169262   0.08353554\n","  0.05090265]\n","MSE: 91.75\n","MAE: 7.13\n","Coefficients: \n"," [-0.39676544 -0.15385115 -0.26598659 ... -0.30876761  0.06883349\n","  0.0375707 ]\n","MSE: 279.19\n","MAE: 13.90\n","Coefficients: \n"," [-0.33397281 -0.11978459 -0.29068158 ... -0.30230042  0.11860841\n","  0.07408682]\n","MSE: 129.04\n","MAE: 9.81\n","Coefficients: \n"," [-0.31308137 -0.10518464 -0.28399393 ... -0.33614045  0.06070024\n","  0.00998397]\n","MSE: 48.44\n","MAE: 6.41\n","Coefficients: \n"," [-0.34481058 -0.14532689 -0.33430338 ... -0.31202966  0.08995211\n","  0.04094853]\n","MSE: 121.37\n","MAE: 8.89\n","Coefficients: \n"," [-0.28927744 -0.08623388 -0.29420224 ... -0.31481103  0.06845545\n","  0.01065809]\n","MSE: 99.25\n","MAE: 8.68\n","Coefficients: \n"," [-0.32541342 -0.0972766  -0.27700306 ... -0.31487813  0.08606098\n","  0.02290777]\n","MSE: 53.61\n","MAE: 6.23\n","Coefficients: \n"," [-0.30755641 -0.10086629 -0.29067588 ... -0.28141121  0.09649759\n","  0.05734758]\n","MSE: 80.63\n","MAE: 7.04\n","Coefficients: \n"," [-0.32193026 -0.10922676 -0.29718541 ... -0.31322958  0.09291099\n","  0.03223186]\n","MSE: 64.84\n","MAE: 6.68\n","Coefficients: \n"," [-0.32482898 -0.11323545 -0.29622954 ... -0.33041781  0.08000964\n","  0.02807315]\n","MSE: 49.39\n","MAE: 4.93\n","Coefficients: \n"," [-0.31617827 -0.10418147 -0.28019571 ... -0.35380999  0.04978783\n","  0.01992094]\n","MSE: 73.54\n","MAE: 7.31\n","Coefficients: \n"," [-0.31765723 -0.09915294 -0.28021942 ... -0.3172035   0.09751941\n","  0.03396417]\n","MSE: 28.95\n","MAE: 4.54\n","Coefficients: \n"," [-0.35709037 -0.14140822 -0.34378879 ... -0.35561228  0.05022014\n"," -0.03238461]\n","MSE: 114.17\n","MAE: 8.46\n","Coefficients: \n"," [-0.29505602 -0.08991844 -0.28466415 ... -0.31076141  0.05261637\n"," -0.00099625]\n","MSE: 49.06\n","MAE: 5.31\n","Coefficients: \n"," [-0.33922453 -0.11811144 -0.30603079 ... -0.31042763  0.08466288\n","  0.04229236]\n","MSE: 143.04\n","MAE: 9.21\n","Coefficients: \n"," [-0.26950653 -0.07596441 -0.28527501 ... -0.29306482  0.11131893\n"," -0.03023392]\n","MSE: 214.35\n","MAE: 12.26\n","Coefficients: \n"," [-0.31898151 -0.10592626 -0.28843713 ... -0.32655771  0.09312142\n","  0.04197685]\n","MSE: 52.41\n","MAE: 5.79\n","Coefficients: \n"," [-0.32220884 -0.11395264 -0.30273674 ... -0.30300618  0.09888321\n","  0.04548144]\n","MSE: 76.30\n","MAE: 7.33\n","Coefficients: \n"," [-0.31991997 -0.12712555 -0.31521485 ... -0.31578415  0.06331566\n","  0.0275904 ]\n","MSE: 51.79\n","MAE: 5.77\n","Coefficients: \n"," [-0.31325704 -0.10240382 -0.28051803 ... -0.3286051   0.10562157\n","  0.05519195]\n","MSE: 128.12\n","MAE: 8.69\n","Coefficients: \n"," [-0.29688349 -0.09582717 -0.28782655 ... -0.3321463   0.08558321\n","  0.04294224]\n","MSE: 78.55\n","MAE: 7.50\n","Coefficients: \n"," [-0.28639695 -0.06145607 -0.26375003 ... -0.27784407  0.12279357\n","  0.05007007]\n","MSE: 126.34\n","MAE: 8.57\n","Coefficients: \n"," [-0.3299226  -0.11011733 -0.29102329 ... -0.28820008  0.10825435\n","  0.05585491]\n","MSE: 40.00\n","MAE: 5.41\n","Coefficients: \n"," [-0.32148323 -0.12130387 -0.29519814 ... -0.31549056  0.08939858\n","  0.02423844]\n","MSE: 98.26\n","MAE: 8.22\n","Coefficients: \n"," [-0.31112918 -0.10297436 -0.28446984 ... -0.33975979  0.07303082\n","  0.02411612]\n","MSE: 53.40\n","MAE: 5.82\n","Coefficients: \n"," [-0.29898919 -0.07139354 -0.24183596 ... -0.38367436  0.05064845\n","  0.02387657]\n","MSE: 92.92\n","MAE: 8.35\n","Coefficients: \n"," [-0.35106455 -0.11704396 -0.27863486 ... -0.29837019  0.06151295\n","  0.01974023]\n","MSE: 336.65\n","MAE: 14.51\n","Coefficients: \n"," [-0.32525519 -0.10771821 -0.29119828 ... -0.3163887   0.08844509\n","  0.02357835]\n","MSE: 44.47\n","MAE: 5.78\n","Coefficients: \n"," [-0.32403001 -0.11359738 -0.2976198  ... -0.33026935  0.07913607\n","  0.01639991]\n","MSE: 70.84\n","MAE: 7.31\n","Coefficients: \n"," [-0.3252185  -0.10690632 -0.28676596 ... -0.30809801  0.10251926\n","  0.03496487]\n","MSE: 67.77\n","MAE: 6.54\n","Coefficients: \n"," [-0.31694098 -0.10741602 -0.28984869 ... -0.31336833  0.08211157\n","  0.03021591]\n","MSE: 28.61\n","MAE: 4.05\n","Coefficients: \n"," [-0.31922575 -0.11252159 -0.2973456  ... -0.33313214  0.07479837\n","  0.01738196]\n","MSE: 31.67\n","MAE: 5.03\n","Coefficients: \n"," [-0.32960034 -0.08598153 -0.30173877 ... -0.31861252  0.07743844\n","  0.01795445]\n","MSE: 170.94\n","MAE: 9.61\n","Coefficients: \n"," [-0.33396449 -0.11496777 -0.30257843 ... -0.3232267   0.09819908\n","  0.04286827]\n","MSE: 51.04\n","MAE: 5.94\n","Coefficients: \n"," [-0.25015363 -0.07563263 -0.21282313 ... -0.33302852  0.0641886\n","  0.06011402]\n","MSE: 227.50\n","MAE: 12.44\n","Coefficients: \n"," [-0.31762625 -0.1201072  -0.26214706 ... -0.27537025  0.06687193\n","  0.01605893]\n","MSE: 376.24\n","MAE: 15.12\n","Coefficients: \n"," [-0.28507477 -0.07253553 -0.26370662 ... -0.31766374  0.09312363\n","  0.03373791]\n","MSE: 72.68\n","MAE: 7.34\n","Coefficients: \n"," [-0.31381607 -0.10474053 -0.28779117 ... -0.30022289  0.10343819\n","  0.0406455 ]\n","MSE: 84.15\n","MAE: 8.27\n","Coefficients: \n"," [-0.33258862 -0.11221989 -0.2872103  ... -0.33701816  0.07337521\n","  0.01768616]\n","MSE: 70.61\n","MAE: 7.67\n","Coefficients: \n"," [-0.33536693 -0.114599   -0.29856166 ... -0.26175331  0.08730607\n","  0.01566273]\n","MSE: 55.00\n","MAE: 6.89\n","Coefficients: \n"," [-0.29888801 -0.07793625 -0.25968916 ... -0.32433626  0.07768861\n","  0.02770292]\n","MSE: 69.14\n","MAE: 7.10\n","Coefficients: \n"," [-0.33895646 -0.10777015 -0.28910878 ... -0.30154993  0.09090845\n","  0.00845877]\n","MSE: 70.96\n","MAE: 6.68\n","Coefficients: \n"," [-0.33661174 -0.12248736 -0.30661143 ... -0.30013065  0.08543224\n","  0.0264337 ]\n","MSE: 31.94\n","MAE: 4.55\n","Coefficients: \n"," [-0.31768253 -0.10062235 -0.28281903 ... -0.30595746  0.08340122\n","  0.02207254]\n","MSE: 42.84\n","MAE: 4.89\n","Coefficients: \n"," [-0.3323191  -0.12615977 -0.29493101 ... -0.31433311  0.08662691\n","  0.03187209]\n","MSE: 41.64\n","MAE: 5.02\n","Coefficients: \n"," [-0.32434752 -0.10247988 -0.2938703  ... -0.27350284  0.07884821\n","  0.02331058]\n","MSE: 75.90\n","MAE: 7.54\n","Coefficients: \n"," [-0.32874618 -0.12463779 -0.30479464 ... -0.29126744  0.12464631\n","  0.0323945 ]\n","MSE: 132.89\n","MAE: 9.74\n","Coefficients: \n"," [-0.33037032 -0.11626846 -0.30687073 ... -0.31983989  0.06340837\n","  0.03069526]\n","MSE: 34.61\n","MAE: 4.80\n","Coefficients: \n"," [-0.34917345 -0.12827566 -0.30882335 ... -0.30171021  0.10688545\n","  0.0333331 ]\n","MSE: 63.77\n","MAE: 6.35\n","Coefficients: \n"," [-0.3177914  -0.11412912 -0.27531873 ... -0.2659776  -0.02528033\n"," -0.12665995]\n","MSE: 485.37\n","MAE: 17.39\n","Coefficients: \n"," [-0.32236196 -0.10838864 -0.29012824 ... -0.30167307  0.04202627\n"," -0.02689219]\n","MSE: 80.53\n","MAE: 7.85\n","Coefficients: \n"," [-0.32485843 -0.10883256 -0.29343379 ... -0.33454548  0.08783585\n","  0.02831495]\n","MSE: 52.82\n","MAE: 6.42\n","Coefficients: \n"," [-0.33467348 -0.1244027  -0.28727292 ... -0.31881345  0.05241692\n"," -0.03208127]\n","MSE: 104.66\n","MAE: 8.87\n","Coefficients: \n"," [-0.30128761 -0.09783106 -0.26990655 ... -0.31255888  0.08400377\n","  0.0196319 ]\n","MSE: 57.08\n","MAE: 6.72\n","Coefficients: \n"," [-0.31762544 -0.09771495 -0.28033099 ... -0.31034497  0.13144587\n","  0.07801256]\n","MSE: 132.37\n","MAE: 9.86\n","Coefficients: \n"," [-0.3124745  -0.0998004  -0.29276641 ... -0.30955913  0.10103431\n","  0.04841496]\n","MSE: 55.29\n","MAE: 6.80\n","Coefficients: \n"," [-0.34082571 -0.11716503 -0.30722032 ... -0.28755876  0.11535363\n","  0.05668343]\n","MSE: 74.12\n","MAE: 6.96\n","Coefficients: \n"," [-0.33954617 -0.0971515  -0.2568399  ... -0.30752703  0.06309228\n","  0.02190226]\n","MSE: 73.72\n","MAE: 7.23\n","Coefficients: \n"," [-0.25393533 -0.0903887  -0.29331987 ... -0.35163864  0.07089289\n","  0.02334475]\n","MSE: 130.38\n","MAE: 9.43\n","Coefficients: \n"," [-0.34647174 -0.12295693 -0.28844341 ... -0.31497066  0.0793277\n","  0.00379992]\n","MSE: 167.67\n","MAE: 10.12\n","Coefficients: \n"," [-0.30997987 -0.10595576 -0.26623111 ... -0.30279254  0.07712087\n","  0.00946316]\n","MSE: 36.04\n","MAE: 5.29\n","Coefficients: \n"," [-0.32584382 -0.11652941 -0.29421319 ... -0.33309504  0.06828643\n","  0.01638697]\n","MSE: 35.28\n","MAE: 5.11\n","Coefficients: \n"," [-0.31664266 -0.10529895 -0.29164584 ... -0.31267203  0.08873366\n","  0.02464314]\n","MSE: 98.64\n","MAE: 8.64\n","Coefficients: \n"," [-0.28823242 -0.11098426 -0.2946839  ... -0.32449586  0.10525228\n","  0.0151269 ]\n","MSE: 84.31\n","MAE: 8.19\n","Coefficients: \n"," [-0.32089674 -0.12061345 -0.28791107 ... -0.31500844  0.11212226\n","  0.05544025]\n","MSE: 52.52\n","MAE: 5.48\n","Coefficients: \n"," [-0.35567433 -0.11042846 -0.27597199 ... -0.30228432  0.11643233\n","  0.09186945]\n","MSE: 113.90\n","MAE: 8.79\n","Coefficients: \n"," [-0.33985033 -0.11137237 -0.26633286 ... -0.34461788  0.08417724\n","  0.02943081]\n","MSE: 91.19\n","MAE: 7.88\n","Coefficients: \n"," [-0.27657321 -0.07012223 -0.25194589 ... -0.32175653  0.06398873\n","  0.00611145]\n","MSE: 77.54\n","MAE: 7.23\n","Coefficients: \n"," [-0.32246276 -0.10733544 -0.29330985 ... -0.34741462  0.10722344\n","  0.06557096]\n","MSE: 88.36\n","MAE: 7.40\n","Coefficients: \n"," [-0.31686221 -0.10176907 -0.29334103 ... -0.32828952  0.0917859\n","  0.03725731]\n","MSE: 44.20\n","MAE: 6.09\n","[10.95062992  6.75634724 21.33860122 16.39570699 18.79612608 18.97855465\n"," 14.1845874   8.75641003  5.40426263  4.97287929  7.80294654  8.63497162\n","  7.12910056 13.89988376  9.81460705  6.40789251  8.88585739  8.67752031\n","  6.232148    7.0429354   6.68349341  4.92648409  7.3126048   4.54303088\n","  8.46499529  5.30605358  9.20839799 12.2634809   5.78739504  7.32794324\n","  5.77426813  8.6882561   7.49672419  8.56796916  5.41028911  8.22177409\n","  5.81601541  8.34934428 14.50544107  5.77836656  7.31348033  6.54289524\n","  4.04860615  5.03468947  9.60520462  5.93617151 12.44460437 15.12200124\n","  7.34340507  8.27071394  7.66782426  6.88811173  7.10397773  6.68196787\n","  4.55089392  4.88881001  5.02328042  7.53935105  9.73541881  4.7994022\n","  6.34558624 17.39482916  7.85073455  6.41630404  8.87284362  6.71654519\n","  9.86463075  6.80186197  6.96161118  7.23059269  9.43013085 10.12034838\n","  5.29479496  5.11028382  8.63721431  8.18905621  5.47857359  8.79094331\n","  7.87618873  7.2297409   7.40048528  6.09391152]\n","8.318808745251182\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"akHx-qdbieo3","outputId":"4aa0be04-aea4-4847-f3ca-baa53888feb2","executionInfo":{"status":"ok","timestamp":1584308478098,"user_tz":240,"elapsed":166761,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model_Lasso = Lasso(alpha = 0.2)\n","acc = regressionModel(model_Lasso)\n","print(acc)\n","# Average MAE\n","print(acc.mean())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 172.43\n","MAE: 10.15\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 85.31\n","MAE: 7.22\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 784.73\n","MAE: 23.30\n","Coefficients: \n"," [-0.  0. -0. ... -0. -0. -0.]\n","MSE: 545.94\n","MAE: 19.24\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 650.17\n","MAE: 23.15\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 818.75\n","MAE: 25.66\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 297.75\n","MAE: 14.62\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 135.59\n","MAE: 9.51\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 34.90\n","MAE: 4.82\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 44.58\n","MAE: 5.32\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 106.31\n","MAE: 8.25\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 110.75\n","MAE: 9.42\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 139.60\n","MAE: 8.69\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 250.43\n","MAE: 12.61\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 113.44\n","MAE: 8.63\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 62.72\n","MAE: 6.35\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 139.53\n","MAE: 9.22\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 96.97\n","MAE: 8.34\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 52.18\n","MAE: 6.05\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 100.43\n","MAE: 8.69\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 120.70\n","MAE: 9.25\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 59.97\n","MAE: 6.18\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 63.20\n","MAE: 6.82\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 45.84\n","MAE: 5.63\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 103.33\n","MAE: 8.41\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 39.77\n","MAE: 4.69\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 139.30\n","MAE: 8.60\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 224.54\n","MAE: 12.55\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 60.95\n","MAE: 6.68\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 77.39\n","MAE: 7.48\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 72.03\n","MAE: 7.69\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 122.39\n","MAE: 8.35\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 112.36\n","MAE: 8.88\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 129.38\n","MAE: 9.41\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 54.53\n","MAE: 5.93\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 85.63\n","MAE: 7.55\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 61.86\n","MAE: 6.61\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 86.66\n","MAE: 8.05\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 326.93\n","MAE: 13.70\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 55.83\n","MAE: 6.17\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 61.69\n","MAE: 6.71\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 87.59\n","MAE: 7.22\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 38.51\n","MAE: 5.13\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 42.46\n","MAE: 4.97\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 162.79\n","MAE: 10.16\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 73.89\n","MAE: 6.66\n","Coefficients: \n"," [-0.  0. -0. ... -0. -0. -0.]\n","MSE: 222.21\n","MAE: 11.10\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 397.00\n","MAE: 15.77\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 53.89\n","MAE: 6.20\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 72.11\n","MAE: 7.33\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 60.22\n","MAE: 6.31\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 48.86\n","MAE: 6.25\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 66.88\n","MAE: 6.84\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 59.84\n","MAE: 6.74\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 36.60\n","MAE: 5.19\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 59.72\n","MAE: 6.45\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 39.70\n","MAE: 5.46\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 121.57\n","MAE: 9.43\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 86.71\n","MAE: 8.17\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 41.03\n","MAE: 4.62\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 63.31\n","MAE: 6.80\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 533.09\n","MAE: 18.29\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 64.38\n","MAE: 7.33\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 57.35\n","MAE: 6.46\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 83.44\n","MAE: 7.78\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 65.68\n","MAE: 7.06\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 149.43\n","MAE: 10.68\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 54.50\n","MAE: 6.56\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 63.47\n","MAE: 7.27\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 56.75\n","MAE: 6.48\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 198.07\n","MAE: 11.84\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 148.04\n","MAE: 9.33\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 41.43\n","MAE: 5.62\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 35.52\n","MAE: 4.73\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 79.92\n","MAE: 7.95\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 106.64\n","MAE: 8.99\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 77.35\n","MAE: 7.03\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 108.66\n","MAE: 8.89\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 87.09\n","MAE: 8.12\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 85.02\n","MAE: 7.52\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 88.15\n","MAE: 8.46\n","Coefficients: \n"," [-0. -0. -0. ... -0. -0. -0.]\n","MSE: 82.40\n","MAE: 8.15\n","[10.15053126  7.21772391 23.29974542 19.23511426 23.14584311 25.65920601\n"," 14.6176363   9.51216538  4.82476471  5.3202714   8.24868639  9.4174069\n","  8.68713777 12.60776817  8.63438089  6.34834007  9.222997    8.34352768\n","  6.04551866  8.69479499  9.24674047  6.18476055  6.82237528  5.63301481\n","  8.41104981  4.69152414  8.60261942 12.54679963  6.67837871  7.48025901\n","  7.68895333  8.35140131  8.88376589  9.40655763  5.93265975  7.55402396\n","  6.60958066  8.05287051 13.70227046  6.17382251  6.71050085  7.22317237\n","  5.12733307  4.96885486 10.16147819  6.6597932  11.10312499 15.76577594\n","  6.19708879  7.33428473  6.30931879  6.24614184  6.84452311  6.7416699\n","  5.1864285   6.45284947  5.46496885  9.4255234   8.16694841  4.61777183\n","  6.79558356 18.2858727   7.33204723  6.46024394  7.78419806  7.06229364\n"," 10.67783028  6.55918253  7.27106832  6.47935844 11.83586104  9.33193514\n","  5.62465362  4.72989716  7.95314115  8.98778403  7.03041402  8.88959573\n","  8.11960325  7.52101833  8.45976334  8.15107611]\n","8.730938546371114\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QrJBJFdIieo8","outputId":"8e8253ae-60bd-4673-81de-086a30252978","executionInfo":{"status":"ok","timestamp":1584308510263,"user_tz":240,"elapsed":198919,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model_ElasticNet = ElasticNet(alpha = 0.1, l1_ratio=0.5)\n","acc = regressionModel(model_ElasticNet)\n","print(acc)\n","# Average MAE\n","print(acc.mean())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Coefficients: \n"," [-0.         -0.         -0.         ... -0.15959247 -0.\n"," -0.        ]\n","MSE: 162.64\n","MAE: 10.02\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.28262415 -0.\n"," -0.        ]\n","MSE: 72.91\n","MAE: 6.69\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.24639398 -0.\n"," -0.        ]\n","MSE: 697.22\n","MAE: 21.71\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.15360886 -0.\n"," -0.        ]\n","MSE: 476.07\n","MAE: 16.60\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.06072001 -0.\n"," -0.        ]\n","MSE: 543.70\n","MAE: 19.99\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.42595064 -0.\n"," -0.        ]\n","MSE: 609.00\n","MAE: 21.16\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.21401053 -0.\n"," -0.        ]\n","MSE: 267.30\n","MAE: 14.01\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20975839 -0.\n"," -0.        ]\n","MSE: 112.83\n","MAE: 9.01\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.19370569 -0.\n"," -0.        ]\n","MSE: 29.84\n","MAE: 4.62\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.26389919 -0.\n"," -0.        ]\n","MSE: 31.88\n","MAE: 4.38\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.14916446 -0.\n"," -0.        ]\n","MSE: 97.42\n","MAE: 7.70\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.17937563 -0.\n"," -0.        ]\n","MSE: 95.21\n","MAE: 8.54\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21222035 -0.\n"," -0.        ]\n","MSE: 111.24\n","MAE: 7.80\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21691287 -0.\n"," -0.        ]\n","MSE: 264.75\n","MAE: 13.49\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.18778577 -0.\n"," -0.        ]\n","MSE: 124.97\n","MAE: 9.52\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.27781069 -0.\n"," -0.        ]\n","MSE: 53.51\n","MAE: 6.50\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.17410556 -0.\n"," -0.        ]\n","MSE: 105.37\n","MAE: 8.15\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.22010974 -0.\n"," -0.        ]\n","MSE: 104.98\n","MAE: 8.91\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20628545 -0.\n"," -0.        ]\n","MSE: 51.75\n","MAE: 6.26\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.14713753 -0.\n"," -0.        ]\n","MSE: 92.02\n","MAE: 7.86\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21805838 -0.\n"," -0.        ]\n","MSE: 78.88\n","MAE: 7.23\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.22940011 -0.\n"," -0.        ]\n","MSE: 50.71\n","MAE: 5.05\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.28970589 -0.\n"," -0.        ]\n","MSE: 69.98\n","MAE: 7.32\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20720886 -0.\n"," -0.        ]\n","MSE: 29.36\n","MAE: 4.60\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.30161945 -0.\n"," -0.        ]\n","MSE: 99.60\n","MAE: 8.24\n","Coefficients: \n"," [-0.         0.        -0.        ... -0.2129776 -0.        -0.       ]\n","MSE: 39.71\n","MAE: 4.89\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21584851 -0.\n"," -0.        ]\n","MSE: 140.01\n","MAE: 8.99\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.16304328 -0.\n"," -0.        ]\n","MSE: 213.04\n","MAE: 11.99\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.22313041 -0.\n"," -0.        ]\n","MSE: 45.33\n","MAE: 5.30\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.18091033 -0.\n"," -0.        ]\n","MSE: 66.50\n","MAE: 6.89\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21752533 -0.\n"," -0.        ]\n","MSE: 52.22\n","MAE: 6.31\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.22985188 -0.\n"," -0.        ]\n","MSE: 118.62\n","MAE: 8.55\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.23681371 -0.\n"," -0.        ]\n","MSE: 85.41\n","MAE: 7.57\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.18900997 -0.\n"," -0.        ]\n","MSE: 118.27\n","MAE: 8.32\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.15601931 -0.\n"," -0.        ]\n","MSE: 39.66\n","MAE: 5.02\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21562988 -0.\n"," -0.        ]\n","MSE: 91.95\n","MAE: 8.17\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.26056056 -0.\n"," -0.        ]\n","MSE: 52.58\n","MAE: 5.80\n","Coefficients: \n"," [-0.        0.       -0.       ... -0.331421 -0.       -0.      ]\n","MSE: 90.14\n","MAE: 8.26\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.19461261 -0.\n"," -0.        ]\n","MSE: 341.88\n","MAE: 14.40\n","Coefficients: \n"," [-0.        -0.        -0.        ... -0.2146731 -0.        -0.       ]\n","MSE: 47.01\n","MAE: 5.91\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24836937 -0.\n"," -0.        ]\n","MSE: 61.90\n","MAE: 6.86\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.18904632 -0.\n"," -0.        ]\n","MSE: 73.18\n","MAE: 6.79\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21124306 -0.\n"," -0.        ]\n","MSE: 30.80\n","MAE: 4.23\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24558695 -0.\n"," -0.        ]\n","MSE: 31.75\n","MAE: 4.57\n","Coefficients: \n"," [-0.        -0.        -0.        ... -0.2399214 -0.        -0.       ]\n","MSE: 156.48\n","MAE: 9.36\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.23169795 -0.\n"," -0.        ]\n","MSE: 56.39\n","MAE: 6.15\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.27118877 -0.\n"," -0.        ]\n","MSE: 229.56\n","MAE: 11.97\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.19256202 -0.\n"," -0.        ]\n","MSE: 369.17\n","MAE: 15.32\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.21704738 -0.\n"," -0.        ]\n","MSE: 67.97\n","MAE: 7.22\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.17875931 -0.\n"," -0.        ]\n","MSE: 76.88\n","MAE: 7.55\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24771849 -0.\n"," -0.        ]\n","MSE: 69.21\n","MAE: 7.41\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.11518638 -0.\n"," -0.        ]\n","MSE: 52.39\n","MAE: 6.64\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.24243148 -0.\n"," -0.        ]\n","MSE: 64.93\n","MAE: 6.67\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.18818303 -0.\n"," -0.        ]\n","MSE: 64.27\n","MAE: 6.47\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.18722472 -0.\n"," -0.        ]\n","MSE: 31.12\n","MAE: 4.69\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20857698 -0.\n"," -0.        ]\n","MSE: 37.91\n","MAE: 4.68\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.22541657 -0.\n"," -0.        ]\n","MSE: 32.68\n","MAE: 4.81\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.17084006 -0.\n"," -0.        ]\n","MSE: 88.17\n","MAE: 8.25\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.16430484 -0.\n"," -0.        ]\n","MSE: 107.59\n","MAE: 8.76\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20938106 -0.\n"," -0.        ]\n","MSE: 38.60\n","MAE: 4.60\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.19314887 -0.\n"," -0.        ]\n","MSE: 59.61\n","MAE: 6.26\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.16651901 -0.\n"," -0.        ]\n","MSE: 475.63\n","MAE: 17.15\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20823821 -0.\n"," -0.        ]\n","MSE: 63.06\n","MAE: 6.97\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24101207 -0.\n"," -0.        ]\n","MSE: 51.25\n","MAE: 6.25\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21175078 -0.\n"," -0.        ]\n","MSE: 91.69\n","MAE: 8.39\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.24976832 -0.\n"," -0.        ]\n","MSE: 57.00\n","MAE: 6.89\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.20209199 -0.\n"," -0.        ]\n","MSE: 133.82\n","MAE: 10.02\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.19843092 -0.\n"," -0.        ]\n","MSE: 54.98\n","MAE: 6.76\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.15672717 -0.\n"," -0.        ]\n","MSE: 65.02\n","MAE: 6.73\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20962851 -0.\n"," -0.        ]\n","MSE: 60.99\n","MAE: 6.48\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.26853438 -0.\n"," -0.        ]\n","MSE: 136.75\n","MAE: 9.87\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.22916858 -0.\n"," -0.        ]\n","MSE: 152.32\n","MAE: 9.70\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.19360709 -0.\n"," -0.        ]\n","MSE: 36.17\n","MAE: 5.01\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.25315935 -0.\n"," -0.        ]\n","MSE: 27.20\n","MAE: 4.30\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.21555712 -0.\n"," -0.        ]\n","MSE: 91.70\n","MAE: 8.20\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.23118906 -0.\n"," -0.        ]\n","MSE: 91.04\n","MAE: 8.43\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.20906227 -0.\n"," -0.        ]\n","MSE: 64.03\n","MAE: 6.19\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.16055438 -0.\n"," -0.        ]\n","MSE: 118.25\n","MAE: 8.87\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.27927845 -0.\n"," -0.        ]\n","MSE: 91.10\n","MAE: 8.08\n","Coefficients: \n"," [-0.          0.         -0.         ... -0.24838581 -0.\n"," -0.        ]\n","MSE: 74.70\n","MAE: 7.06\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24963055 -0.\n"," -0.        ]\n","MSE: 76.45\n","MAE: 7.01\n","Coefficients: \n"," [-0.         -0.         -0.         ... -0.24647127 -0.\n"," -0.        ]\n","MSE: 49.38\n","MAE: 6.53\n","[10.02377372  6.69307454 21.71392274 16.59776308 19.98562047 21.16372507\n"," 14.00500578  9.01283908  4.61987289  4.38044715  7.70328387  8.5377419\n","  7.79822176 13.48855335  9.51695581  6.49553273  8.14775724  8.91339275\n","  6.25557115  7.85819193  7.22748553  5.05016624  7.31992835  4.60481139\n","  8.23825079  4.88758781  8.98827357 11.99436048  5.3024959   6.88621312\n","  6.30811743  8.54740882  7.56714931  8.3234209   5.01620237  8.1734356\n","  5.80055268  8.26162769 14.40011792  5.91107782  6.8642894   6.78822473\n","  4.22995945  4.57486064  9.36160312  6.15317957 11.9666799  15.32099837\n","  7.21814949  7.55486318  7.40658665  6.63902301  6.66511565  6.46503438\n","  4.6942941   4.67620568  4.8114724   8.25173586  8.7588325   4.59764099\n","  6.26277547 17.15374036  6.97353514  6.25124705  8.38993124  6.88952502\n"," 10.01548131  6.757234    6.72651647  6.47749472  9.87017732  9.70050249\n","  5.01114353  4.30100729  8.2026361   8.43153893  6.19074347  8.87053028\n","  8.08438276  7.0550416   7.00529679  6.52986145]\n","8.242305153610799\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2QhN10tlKOgk"},"source":["## Partie 2: Explorez les algorithmes de classification (FER dataset)\n","\n","Vous devez reprendre l'ensemble FER et les primitives que vouz avez choisi dans le laboratoire 1.\n","\n","Dans ce partie vous devez explorer le algorithmes de classification <b> régression logistique et réseaux de neurones multicouches (MLP) </b>\n","\n","Vouz devez comparer la performance de ces algorithmes pour l'ensemble FER sur:\n","\n","\n","#### 1) Le vecteur de pixels (images vectorisés)\n","#### 2) Vecteur de primitives (reprendre les primitives du lab 1)\n","#### 3) Vecteur de primitives selectionés/transformés (reprendre les primitives du lab 1)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MvgQUd-GKOgo"},"source":["### <font color=blue> (2a) Charger le fichier de données</font> "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ooVVdw7KKOgr","outputId":"ab6b6e07-ed53-45c8-e71f-29aa5dc12ca6","executionInfo":{"status":"error","timestamp":1584308513030,"user_tz":240,"elapsed":201683,"user":{"displayName":"Imane Zriaa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioDY4dLkpnQFW2LMOcW3EpM23co77w9n8Vs1QD=s64","userId":"18312604134454482575"}},"colab":{"base_uri":"https://localhost:8080/","height":389}},"source":["# Load data\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","# load data\n","ferData = np.loadtxt('fer2013.csv', delimiter=',', dtype=np.str)\n","Xtrain = np.ones((28709,2304),np.uint8)\n","for i in range(1, 28710):\n","\tXtrain[i-1]=ferData[i,1].split(\" \")\n","\n","ytrain=ferData[1:28710,0].astype(np.int)\n","Xval = np.ones((3589,2304),float)\n","for i in range(28710, 32299):\n","\tXval[i-28710]=ferData[i,1].split(\" \")\n","\n","yval=ferData[28710:32299,0].astype(np.int)\n","Xtest = np.ones((3589,2304),float)\n","for i in range(32299, 35888):\n","\tXtest[i-32299]=ferData[i,1].split(\" \")\n","\n","ytest=ferData[32299:,0].astype(np.int)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-62af1f59b592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mferData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fer2013.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28709\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2304\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28710\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: fer2013.csv not found."]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zNFLpEwOKb8B"},"source":["#### Charger vector 2 (SIFT et LBP)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Au4xXcgnKa62","colab":{}},"source":["#LBP\n","lbp_vector_app = numpy.genfromtxt('lbp_vector_app.csv', delimiter=';')\n","lbp_vector_app_x = lbp_vector_app[:,:-1]#Prendre les features(x)\n","\n","lbp_vector_val = numpy.genfromtxt('lbp_vector_val.csv', delimiter=';')\n","lbp_vector_val_x = lbp_vector_val[:,:-1]#Prendre les features(x)\n","\n","lbp_vector_test = numpy.genfromtxt('lbp_vector_test.csv', delimiter=';')\n","lbp_vector_test_x = lbp_vector_test[:,:-1]#Prendre les features(x)\n","\n","#SIFT\n","sift_vector_app = numpy.genfromtxt('sift_vector_app.csv', delimiter=';')\n","sift_vector_app_x = sift_vector_app[:,:-1]#Prendre les features(x)\n","\n","sift_vector_val = numpy.genfromtxt('sift_vector_val.csv', delimiter=';')\n","sift_vector_val_x = sift_vector_val[:,:-1]#Prendre les features(x)\n","\n","sift_vector_test = numpy.genfromtxt('sift_vector_test.csv', delimiter=';')\n","sift_vector_test_x = sift_vector_test[:,:-1]#Prendre les features(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"to-B_Ik7KoOl"},"source":["#### Charger vector 3 ( Filter univariate Variance Threhold & PCA )\n","\n"]},{"cell_type":"code","metadata":{"id":"niLtQ6sW5Qzn","colab_type":"code","colab":{}},"source":["\"\"\"Filter Univariate Variance Threhold  \"\"\" \n","#LBP\n","FS_th_lbp_vector_app = numpy.genfromtxt('FS_th_lbp_vector_app.csv', delimiter=';')\n","FS_th_lbp_vector_val = numpy.genfromtxt('FS_th_lbp_vector_val.csv', delimiter=';')\n","FS_th_lbp_vector_test = numpy.genfromtxt('FS_th_lbp_vector_test.csv', delimiter=';')\n","\n","#SIFT\n","FS_th_sift_vector_app = numpy.genfromtxt('FS_th_sift_vector_app.csv', delimiter=';')\n","FS_th_sift_vector_val = numpy.genfromtxt('FS_th_sift_vector_val.csv', delimiter=';')\n","FS_th_sift_vector_test = numpy.genfromtxt('FS_th_sift_vector_test.csv', delimiter=';')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"flOzWMsV6ZWL","colab_type":"code","colab":{}},"source":["\"\"\"PCA\"\"\"\n","#SIFT\n","PCA_sift_vector_app = numpy.genfromtxt('PCA_sift_vector_app.csv', delimiter=';')\n","PCA_sift_vector_val = numpy.genfromtxt('PCA_sift_vector_val.csv', delimiter=';')\n","PCA_sift_vector_test = numpy.genfromtxt('PCA_sift_vector_test.csv', delimiter=';')\n","\n","#LBP\n","PCA_lbp_vector_app = numpy.genfromtxt('PCA_lbp_vector_app.csv', delimiter=';')\n","PCA_lbp_vector_val = numpy.genfromtxt('PCA_lbp_vector_val.csv', delimiter=';')\n","PCA_lbp_vector_test = numpy.genfromtxt('PCA_lbp_vector_test.csv', delimiter=';')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-K7ZP795_7H","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"006nEVflnmSW","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t4WJU6exKyYY"},"source":["### Normaliser \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a-F5C4R6K9D0","colab":{}},"source":["scaler = MinMaxScaler(feature_range=(0, 1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TxSg9m4qK2tn"},"source":["Normalizer FER"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-berK9hQK25m","colab":{}},"source":["Xtrain = scaler.fit_transform(Xtrain)\n","Xval = scaler.fit_transform(Xval)\n","Xtest = scaler.fit_transform(Xtest)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QyKm5HfBK3Db"},"source":["Normalize Vector 2"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PAwmSe2PK3M9","colab":{}},"source":["lbp_vector_app_x = scaler.fit_transform(lbp_vector_app_x)\n","lbp_vector_val_x = scaler.fit_transform(lbp_vector_val_x)\n","lbp_vector_test_x = scaler.fit_transform(lbp_vector_test_x)\n","\n","sift_vector_app_x = scaler.fit_transform(sift_vector_app_x)\n","sift_vector_val_x = scaler.fit_transform(sift_vector_val_x)\n","sift_vector_test_x = scaler.fit_transform(sift_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qhtp7VUsK3Vt"},"source":["Nomalize vector 3"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fqmnFMnqK3ey","colab":{}},"source":["\"\"\"Filter Univariate Variance Threhold  \"\"\" \n","FS_th_lbp_vector_app = scaler.fit_transform(FS_th_lbp_vector_app)\n","FS_th_lbp_vector_val = scaler.fit_transform(FS_th_lbp_vector_val)\n","FS_th_lbp_vector_test = scaler.fit_transform(FS_th_lbp_vector_test)\n","\n","FS_th_sift_vector_app = scaler.fit_transform(FS_th_sift_vector_app)\n","FS_th_sift_vector_val = scaler.fit_transform(FS_th_sift_vector_val)\n","FS_th_sift_vector_test = scaler.fit_transform(FS_th_sift_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8KJeSTHCGbT","colab_type":"code","colab":{}},"source":["\"\"\"PCA\"\"\"\n","PCA_lbp_vector_app = scaler.fit_transform(PCA_lbp_vector_app)\n","PCA_lbp_vector_val = scaler.fit_transform(PCA_lbp_vector_val)\n","PCA_lbp_vector_test = scaler.fit_transform(PCA_lbp_vector_test)\n","\n","PCA_sift_vector_app = scaler.fit_transform(PCA_sift_vector_app)\n","PCA_sift_vector_val = scaler.fit_transform(PCA_sift_vector_val)\n","PCA_sift_vector_test = scaler.fit_transform(PCA_sift_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6NeO17X8KOgw"},"source":["### <font color=blue> (2b) Créer et évaluer des modèles de classification (Régression logistique) </font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hS0cfsp5KOgx"},"source":["<font color=blue>\n","    \n","##### À faire:\n","\n","1. Utiliser l'algorithme régression logistique disponible dans [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), pour classifier les trois (3) vecteurs de primitives du laboratoire 1. Vous pouvez regarder aussi [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) et [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV)\n","2. Entraîner et optimiser les paramètres des modèles.\n","3. Faire une analyse des résultats et présenter vos conclusions sur les modèles linéaires.\n","    \n","</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q5IsEp80KOgy"},"source":["###  (2b): Code:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mLjtT09QT8Xz","colab":{}},"source":["# instantiate the model (using the default parameters)\n","def showResultatLogisticRegr(logreg, train, val, test):\n","    y_pred=logreg.predict(train)\n","    print('% Error of logistic regression classifier on train set: {:.2f}'.format(1 - accuracy_score(y_pred, ytrain)))\n","\n","    y_pred=logreg.predict(val)\n","    print('% Error of logistic regression classifier on validation set: {:.2f}'.format(1 - accuracy_score(y_pred, yval)))\n","\n","    y_pred=logreg.predict(test)\n","    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(test, ytest)))\n","    print('% Error of logistic regression classifier on test set: {:.2f}'.format(1 - accuracy_score(y_pred, ytest)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9MkDP0z8T44V"},"source":["Vecteur FER\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Essh-2xjKOg0","colab":{}},"source":["# instantiate the model (using the default parameters) fit the model with data\n","logreg = LogisticRegression().fit(Xtrain,ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0YV6ZDNzMyJ","colab_type":"code","colab":{}},"source":["#resultat pour vecteur FER\n","showResultatLogisticRegr(logreg,Xtrain,Xval,Xtest)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b8Oi0QhMUHM_"},"source":["Vecteur 2 "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qoBKAiGCUJTD"},"source":["SIFT"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dwvHPw_XUGeH","colab":{}},"source":["# instantiate the model (using the default parameters) fit the model with data\n","logreg_sift = LogisticRegression().fit(sift_vector_app_x,ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKXeu6nLzQrR","colab_type":"code","colab":{}},"source":["#resultat pour vecteur SIFT\n","showResultatLogisticRegr(logreg_sift,sift_vector_app_x,sift_vector_val_x,sift_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b-zrJm7_Uacj"},"source":["LBP"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Oa1YpD__Ub09","colab":{}},"source":["# instantiate the model (using the default parameters) fit the model with data\n","logreg_lbp = LogisticRegression().fit(lbp_vector_app_x, ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttMxxM-rzU5s","colab_type":"code","colab":{}},"source":["#resultat pour vecteur LBP\n","showResultatLogisticRegr(logreg_lbp,lbp_vector_app_x,lbp_vector_val_x,lbp_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ha1DYqNDRR2v","colab_type":"text"},"source":["Vecteur 3\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rbttb41aUjem"},"source":["PCA (SIFT/LBP)\n"]},{"cell_type":"code","metadata":{"id":"sanqLbTZnLcX","colab_type":"code","colab":{}},"source":["\"SIFT\"\n","# instantiate the model (using the default parameters) fit the model with data\n","logreg_sift_PCA = LogisticRegression().fit(PCA_sift_vector_app, ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3EqE90FnOhY","colab_type":"code","colab":{}},"source":["showResultatLogisticRegr(logreg_sift_PCA,PCA_sift_vector_app,PCA_sift_vector_val,PCA_sift_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bV8Vz0okPEOT","colab_type":"code","colab":{}},"source":["\"LBP\"\n","# instantiate the model (using the default parameters) fit the model with data\n","logreg_lbp_PCA = LogisticRegression().fit(PCA_lbp_vector_app, ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibX4OiCRzjjD","colab_type":"code","colab":{}},"source":["showResultatLogisticRegr(logreg_lbp_PCA,PCA_lbp_vector_app_x,PCA_lbp_vector_val_x,PCA_lbp_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"syKoM-ttarRJ","colab_type":"text"},"source":["Filter Univariate Variance Threhold\n"]},{"cell_type":"code","metadata":{"id":"oO1KL4x_nYoB","colab_type":"code","colab":{}},"source":["\"SIFT\"\n","# instantiate the model (using the default parameters) fit the model with data\n","logreg_sift_F = LogisticRegression().fit(FS_th_sift_vector_app, ytrain)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Icxz9T_QakZZ","colab_type":"code","colab":{}},"source":["showResultatLogisticRegr(logreg_sift_F,FS_th_sift_vector_app,FS_th_sift_vector_val,FS_th_sift_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbqOGaDCnY8x","colab_type":"code","colab":{}},"source":["\"LBP\"\n","# instantiate the model (using the default parameters) fit the model with data\n","logreg_lbp_F = LogisticRegression().fit(FS_th_lbp_vector_app, ytrain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS--NRrJzmzi","colab_type":"code","colab":{}},"source":["showResultatLogisticRegr(logreg_lbp_F,FS_th_lbp_vector_app,FS_th_lbp_vector_val,FS_th_lbp_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XAv3BKFWPYR","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wmxavlpGKOg7"},"source":["###  (2b): Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F7N9TBEIKOg8"},"source":["\n","| Algorithme       | Paramètres    | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n","|------------------|---------------|-----------|-------------|-------------|-------------|\n","| Regr logistique  | V1-FER        |   0.36  |   51    |   64    |   64    |\n","| Regr logistique  | V2-SIFT       |   0.25    |   74        |   75    |   75    |\n","| Regr logistique  | V2-LBP        |   0.27  |   73    |   74    |   73    |\n","| Regr logistique  | V3-PCA-SIFT   |   0.24 |    75    |   75    |   76    |\n","| Regr logistique  | V3-PCA_LBP    |   0.24  |   75    |   75    |   76    |\n","| Regr logistique  | V3-F-SIFT     |   0.25  |    74    |   75    |   75    |\n","| Regr logistique  | V3-F-LBP      |   0.27  |    74    |   73    |   73    |\n","\n","###Analyse des résultats###\n","Avec l'utilisation de l'ensemble FER et les primitives du laboratoire 1. Cela donne sept ensembles différents, soit le vecteur de pixels, les deux vecteurs de primitives de PCA et de LBP et les deux vecteurs de primitives avec l'application de l'algorithme de feature selection et les deux vecteurs de primitives avec l'algorithme de transformation. Après avoir effectué l'algorithme de classification sur les différents vecteurs soit la régression logistique, on peut voir que les modèles linéaires obtenus ont des résultats assez similaires, soit les ensembles avec les primitives LBP, SIFT, PCA sur SIFT, PCA sur LBP, Filtre sur SIFT et Filtre sur LBP dont les précisions obtenues sont de 24% et 27% avec l'erreur sur l'ensemble entrainement, validation et test sont entre 73% et 76% ce qui est très rapproché. Sauf pour un seul cas, le vecteur de pixels(images vectorisées) a un pourcentage d'erreur de 51% sur l'ensemble d'entrainement et 64% sur la partie validation et test, qui est environ 10% de moins que tous les autres modèles entrainés.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PtUq1uNhKOg9"},"source":["### <font color=blue> (2c) Créer et évaluer des modèles de classification (Réseaux perceptron multi-couche)</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GIyku6JNKOg-"},"source":["<font color=blue>\n","    \n","##### À faire:\n","\n","1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones multi-couche pour classifier les trois\n","(3) vecteurs de primitives du laboratoire 1. \n","2. Choisir l'architecture approprié pour chaque vecteur de primitives (nombre et dimension des couches). \n","2. Entraîner et optimiser les paramètres des réseaux.\n","4. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones.\n","    \n","</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8Czqr-LxKOg_"},"source":["### <font color=blue> (2c) Code</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oV-ng7X2L-ux"},"source":["### One-Hot-Encode Outputs (Labels)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6q5_dd9pKOhA","colab":{}},"source":["ytrain = np_utils.to_categorical(ytrain)\n","yval   = np_utils.to_categorical(yval)\n","ytest  = np_utils.to_categorical(ytest)\n","num_classes = ytest.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"747m_vmTMS44"},"source":["### Configure Tensor Flow and Keras"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hvVYzkxrMQdc","colab":{}},"source":["print(tf.version.VERSION)\n","\n","with tf.compat.v1.Session() as sess:\n","  devices = sess.list_devices()\n","devices\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","config = tf.compat.v1.ConfigProto( )\n","config.gpu_options.allow_growth = True\n","sess   =  tf.compat.v1.Session(config=config)\n","\n","import keras.backend.tensorflow_backend as tf_bkend\n","tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Mc2y-FO7MWQC"},"source":["### Create a MLP Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YJmIiX4nMYlr","colab":{}},"source":["def mlp_model(x_train):\n","    \n","    from keras.layers      import Input, Dense, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, optimizers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","    \n","    from keras.layers.normalization import BatchNormalization\n","        \n","    import keras.initializers as init\n","    \n","    nb_classes = 7\n","    \n","    inp    = Input(shape = x_train[0].shape)\n","    #----------------------\n","    dense1 = Dense(512, activation='relu', name=\"dense1_512\")(inp)\n","    norm1  = BatchNormalization()(dense1)\n","    #----------------------\n","    dense2 = Dense(128, activation='relu', name=\"dense2_128\")(norm1)\n","    drop1  = Dropout(0.50)(dense2)    \n","    #----------------------\n","    out    = Dense(nb_classes, activation='softmax')(drop1)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","\n","#   model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'] )\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta( lr = 1.0, rho = 0.95, epsilon = 1e-08, decay = 0.0),\n","                  metrics = ['accuracy'] )\n","    \n","    model.summary()\n","     \n","    return model "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HbrrkqlcMjHa"},"source":["### Build a model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NxhOjrrkMjZd","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","from livelossplot    import PlotLossesKeras\n","from keras           import optimizers\n","\n","model = mlp_model(Xtrain)\n","\n","model_sift = mlp_model(sift_vector_app_x)\n","model_lbp = mlp_model(lbp_vector_app_x)\n","model_sift_PCA=mlp_model(PCA_sift_vector_app)\n","model_sift_FS_th=mlp_model(FS_th_sift_vector_app)\n","model_lbp_PCA=mlp_model(PCA_lbp_vector_app)\n","model_lbp_FS_th=mlp_model(FS_th_lbp_vector_app)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Atz883CfsgMb","colab_type":"code","colab":{}},"source":["str2 = \".best.hdf5\"\n","\n","filepath = \"weights_FER_512_128\" + str2\n","filepath_sift= \"weights_FER_sift\" + str2\n","filepath_lbp= \"weights_FER_lbp\" + str2\n","filepath_sift_pca= \"weights_FER_sift_pca\"+ str2\n","filepath_sift_fs= \"weights_FER_sift_fs\" + str2\n","filepath_lbp_pca=  \"weights_FER_lbp_pca\" + str2\n","filepath_lbp_fs= \"weights_FER_lbp_fs\" + str2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK13i4PEsjAn","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","from livelossplot    import PlotLossesKeras\n","from keras           import optimizers\n","\n","\n","def  create_callback_list(filepath_to_use):\n","    checkpoint = ModelCheckpoint( filepath_to_use, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max' ) \n","\n","    callbacks_list = [ checkpoint, PlotLossesKeras() ]\n","    return callbacks_list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JIAp73X8MtJ6"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YTR9EtbNMtTu","colab":{}},"source":["hist        = []\n","nb_epoch    = 20\n","batch_size  = 10000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Je2xqG5FM0TA"},"source":["Train FER"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vRpdDzYxMzpJ","colab":{}},"source":["train_steps = Xtrain.shape[0]//batch_size \n","val_steps   = Xval.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model.fit(Xtrain, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks =  create_callback_list(filepath),\n","                      validation_data = (Xval, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d5Px4ntzMtdW"},"source":["Train Vector 2"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yJmKtGcMM7MF"},"source":["SIFT"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Ty1PmJvMtmY","colab":{}},"source":["train_steps = sift_vector_app_x.shape[0]//batch_size \n","val_steps   = sift_vector_val_x.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_sift.fit(sift_vector_app_x, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks =  create_callback_list(filepath_sift),\n","                      validation_data = (sift_vector_val_x, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9SMFlgNmM9qZ"},"source":["LBP"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PfXNIfAFM-uG","colab":{}},"source":["train_steps = lbp_vector_app_x.shape[0]//batch_size \n","val_steps   = lbp_vector_val_x.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_lbp.fit(lbp_vector_app_x, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks =  create_callback_list(filepath_lbp),\n","                      validation_data = (lbp_vector_val_x, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yFYdfVkDsv5v","colab_type":"text"},"source":["### PCA"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RJdPORj0NBc7"},"source":["PCA SIFT"]},{"cell_type":"code","metadata":{"id":"BuFv0mNGo6AU","colab_type":"code","colab":{}},"source":["train_steps = PCA_sift_vector_app.shape[0]//batch_size \n","val_steps   = PCA_sift_vector_val.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_sift_PCA.fit(PCA_sift_vector_app, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = create_callback_list(filepath_sift_pca),\n","                      validation_data = (PCA_sift_vector_val, yval)\n","                     ))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOqSTWDEs1iv","colab_type":"code","colab":{}},"source":["train_steps = PCA_lbp_vector_app.shape[0]//batch_size \n","val_steps   = PCA_lbp_vector_val.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_lbp_PCA.fit(PCA_lbp_vector_app, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = create_callback_list(filepath_lbp_pca),\n","                      validation_data = (PCA_lbp_vector_val, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pczdHwm2s49i","colab_type":"text"},"source":["### Filter Univariate Variance Threhold"]},{"cell_type":"markdown","metadata":{"id":"2zPvvymVs9-L","colab_type":"text"},"source":["SIFT"]},{"cell_type":"code","metadata":{"id":"2z1md2E5s8im","colab_type":"code","colab":{}},"source":["train_steps = FS_th_sift_vector_app.shape[0]//batch_size \n","val_steps   = FS_th_sift_vector_val.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_sift_FS_th.fit(FS_th_sift_vector_app, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = create_callback_list(filepath_lbp_pca),\n","                      validation_data = (FS_th_sift_vector_val, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8O1n57Vas_eC","colab_type":"text"},"source":["LBP"]},{"cell_type":"code","metadata":{"id":"YEUNtGsBtAoB","colab_type":"code","colab":{}},"source":["train_steps = FS_th_lbp_vector_app.shape[0]//batch_size \n","val_steps   =FS_th_lbp_vector_app.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model_lbp_FS_th.fit(FS_th_lbp_vector_app, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = create_callback_list(filepath_lbp_pca),\n","                      validation_data = (FS_th_lbp_vector_val, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"umm9164dNy0E"},"source":["### Evaluate the model"]},{"cell_type":"code","metadata":{"id":"H9rjpIZgDGMS","colab_type":"code","colab":{}},"source":["# instantiate the model (using the default parameters)\n","def showResultatmodel(model, train, val, test):\n","    y_pred=model.evaluate(train, ytrain)\n","    \n","    print(' Error of logistic regression classifier on train set: {:.2f} %'.format(100 - y_pred[1]*100))\n","\n","    y_pred=model.evaluate(val, yval)\n","    print(' Error of logistic regression classifier on validation set: {:.2f} %'.format(100 - y_pred[1]*100))\n","\n","    y_pred=model.evaluate(test, ytest)\n","    print('Accuracy of logistic regression classifier on test set: {:.2f} %'.format(scores[1]*100))\n","    print('Error of logistic regression classifier on test set: {:.2f} %'.format(100 - y_pred[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kM8U9GwaN3Ej"},"source":["Evaluate FER"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"76q2d8CfN6Ws","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(Xtest, ytest, verbose=0)\n","print(\"FER MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model, Xtrain, Xval,  Xtest)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sgAXOH4aN8jF"},"source":["Evaluate vector 2"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iHiVDPFnN-1u"},"source":["Evaluate SIFT"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8NUA4znfOCbJ","colab":{}},"source":["# Final evaluation of the model\n","scores = model_sift.evaluate(sift_vector_test_x, ytest, verbose=0)\n","print(\"SIFT MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_sift, sift_vector_app_x,sift_vector_val_x,sift_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"20w-7e34OEd0"},"source":["Evaluate LBP"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Av-1FXm-OGK_","colab":{}},"source":["# Final evaluation of the model\n","scores = model_lbp.evaluate(lbp_vector_test_x, ytest, verbose=0)\n","print(\"LBP MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_lbp, lbp_vector_app_x,lbp_vector_val_x,lbp_vector_test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ygs5v9qzOIA5"},"source":["Evaluate vector 3"]},{"cell_type":"markdown","metadata":{"id":"Nubd3PEzvXk1","colab_type":"text"},"source":["\n","Filter Univariate Variance Threhold  \n"]},{"cell_type":"code","metadata":{"id":"9nlU1EybvdnR","colab_type":"code","colab":{}},"source":["# Final evaluation of the model#\n","#SIFT# \n","scores = model_sift_FS_th.evaluate(FS_th_sift_vector_test, ytest, verbose=0)\n","print(\"Filter SIFT MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_sift_FS_th, FS_th_sift_vector_app,FS_th_sift_vector_val,FS_th_sift_vector_test)\n","\n","#lbp\n","scores = model_lbp_FS_th.evaluate(Fs_th_lbp_vector_test, ytest, verbose=0)\n","print(\"Filter LBP MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_lbp_FS_th, FS_th_lbp_vector_app,FS_th_lbp_vector_val,FS_th_lbp_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2etCnVZBzOry","colab_type":"text"},"source":["PCA"]},{"cell_type":"code","metadata":{"id":"nyprk8p9zR1w","colab_type":"code","colab":{}},"source":["# Final evaluation of the model#\n","#SIFT# \n","scores = model_sift_PCA.evaluate(PCA_sift_vector_test, ytest, verbose=0)\n","print(\"PCA SIFT MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_sift_PCA, PCA_sift_vector_app,PCA_sift_vector_val,PCA_sift_vector_test)\n","\n","#lbp\n","scores = model_lbp_PCA.evaluate(PCA_lbp_vector_test, ytest, verbose=0)\n","print(\"PCA LBP MLP accuracy: %.2f%%\" % (scores[1]*100))\n","showResultatmodel(model_lbp_PCA, PCA_lbp_vector_app,PCA_lbp_vector_val,PCA_lbp_vector_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_HQPm_JbKOhE"},"source":["### (2c): Résultats et résponses:\n","\n","| Algorithme       | Paramètres    | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n","|------------------|---------------|-----------|-------------|-------------|-------------|\n","| MLP FER      | 0:1180160:2048:65664:0:903        |   29.09  |   70.42    |   69.74    |   70.91    |\n","| MLP SIFT     | 0:66048:2048:65664:0:903 |   14.57  |   86.00    |   87.02    |   85.43    |\n","| MLP LBP      | 0:13824:2048:65664:0:903        |   13.18  |   83.67    |   83.76    |   86.82    |\n","| MLP F SIFT   | 0:1536:2048:65664:0:903       |   17.86  |   84.53    |   82.25    |   82.14    |\n","| MLP F LBP    | 0:25088:2048:65664:0:903         |   14.71  |   85.74    |   86.15    |   85.29    |\n","| MLP PCA SIFT | 0:1536:2048:65664:0:903        |   13.43  |   88.87    |   84.90    |   86.47    |\n","| MLP PCA LBP  | 0:13824:2048:65664:0:903         |   24.49  |   74.89    |   75.06    |   75.51    |\n","\n","###Analyse des résultats###\n","Avec l'utilisation de l'ensemble FER et les primitives du laboratoire 1. Cela donne sept ensembles différents, soit le vecteur de pixels, les deux vecteurs de primitives de PCA et de LBP et les deux vecteurs de primitives avec l'application de l'algorithme de feature selection et les deux vecteurs de primitives avec l'algorithme de transformation. Après avoir utilisé Tensorflow et Keras pour construire un réseau de neurones multicouche pour effectuer la classification des primitives du laboratoire 1. On peut observer selon les résultats des différents vecteurs dans les modèles MLP que la précision de ces réseaux de neurones est sensiblement la même, en effet avec les ensembles LBP, SIFT, PCA sur SIFT, PCA sur LBP, Filtre sur SIFT, ils ont données entre 13% et 17% sur la précision avec comme pourcentage d'erreur sur l'ensemble d'entrainement, de validation et test entre 82% et 86%. Par contre, le modèle entrainé avec le vecteur de pixels(images vectorisées) obtient un meilleur résultat avec une précision de 5% à 15% plus élevé que les autres soit 29.09% et un pourcentage d'erreur de 5% à 15% moins élevé avec les autres modèles, soit 70.42% avec l'ensemble d'entrainement, 69.74% pour l'ensemble de validation et 70.91% pour l'ensemble de test. De plus second modèle entrainé avec le vecteur de primitives LBP avec l'algorithme de transformation qui donne une précision de 24.49% et un pourcentage d'erreur de 74.89% avec l'ensemble d'entrainement, 75.06% pour l'ensemble de validation et 75.51% pour l'ensemble de test.\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ygRpJby2KOhK"},"source":["## Partie 3: Explorez l'apprentissage de la représentation et les réseaux neuronaux profonds (FER dataset et FG-NET dataset)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V-HS0dBKKOhL"},"source":["<font color=black>\n","    \n","##### À faire :\n","1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones convolutif pour apprendre une représentation directement des images de visage aussi que les discriminantes. \n","2. Choisir l’architecture appropriée : nombre de couches convolutifs (CL), dimension des filtres, “stride”, nombre de couches entièrement connectées (FC) et la dimension des couches). \n","3. Entraîner et optimiser les paramètres du réseau.\n","4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n","5. Récupérer une des architectures CNN pré-entraînes disponibles dans Keras pour faire une “transfert de connaissance (transfer learning). Faire un \"fine-tuning\" du modèle choisi sur FER.    \n","7. Choisir le modèle qu’a donné de meilleurs résultats sur FER et l’adapter pour FG-NET.     \n","8. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones.\n","    \n","</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NfTX85PzKOhO"},"source":["<font color=black>\n","    \n","### Partie (3a): Code CNN (FER):\n","    \n","##### À faire:\n","1. Utiliser [Tensorflow et Keras](https://www.tensorflow.org/tutorials/keras/classification) pour construire un réseau de neurones convolutif pour apprendre une représentation directement des images de visage aussi que les discriminantes. \n","2. Choisir l’architecture appropriée: nombre de couches convolutifs (CL), dimension des filtres, \"stride”, nombre de couches entièrement connectées (FC) et la dimension des couches). \n","3. Entraîner et optimiser les paramètres du réseau.\n","4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n","    \n","</font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EukLnu6tKOhP","colab":{}},"source":["# Votre code ici\n","from sklearn.preprocessing import MinMaxScaler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pH-45L840md","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import os\n","import math\n","import tensorflow as tf\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBaBf6Sj40me","colab_type":"text"},"source":["### Fetch data, normalize, reshape and output labels in OHE"]},{"cell_type":"code","metadata":{"id":"xyPIkDd040me","colab_type":"code","colab":{}},"source":["# Load data\n","# Load data\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","# load data\n","ferData = np.loadtxt('fer2013.csv/fer2013.csv', delimiter=',', dtype=np.str)\n","Xtrain = np.ones((28709,2304),np.uint8)\n","for i in range(1, 28710):\n","\tXtrain[i-1]=ferData[i,1].split(\" \")\n","\n","ytrain=ferData[1:28710,0].astype(np.int)\n","Xval = np.ones((3589,2304),float)\n","for i in range(28710, 32299):\n","\tXval[i-28710]=ferData[i,1].split(\" \")\n","\n","yval=ferData[28710:32299,0].astype(np.int)\n","Xtest = np.ones((3589,2304),float)\n","for i in range(32299, 35888):\n","\tXtest[i-32299]=ferData[i,1].split(\" \")\n","\n","ytest=ferData[32299:,0].astype(np.int)\n","\n","# normalize\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","Xtrain = scaler.fit_transform(Xtrain)\n","Xval   = scaler.fit_transform(Xval)\n","Xtest  = scaler.fit_transform(Xtest)\n","\n","# reshape to be [samples][pixels][width][height]\n","Xtrain = Xtrain.reshape(Xtrain.shape[0], 48, 48, 1).astype('float32')\n","Xtest  = Xtest.reshape(Xtest.shape[0], 48, 48, 1).astype('float32')\n","Xval   = Xval.reshape(Xval.shape[0], 48, 48, 1).astype('float32')\n","\n","# Multinomial distribution\n","from keras.utils import np_utils\n","\n","ytrain = np_utils.to_categorical(ytrain)\n","yval   = np_utils.to_categorical(yval)\n","ytest  = np_utils.to_categorical(ytest)\n","\n","num_classes = ytest.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZNehO_p40mg","colab_type":"text"},"source":["### Configure TensorFlow and Keras"]},{"cell_type":"code","metadata":{"id":"-zZzj_lY40mh","colab_type":"code","colab":{}},"source":["print(tf.version.VERSION)\n","\n","\n","with tf.compat.v1.Session() as sess:\n","  devices = sess.list_devices()\n","devices\n","\n","#Use \"0\" if you have a GPU card\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","config = tf.compat.v1.ConfigProto( )\n","config.gpu_options.allow_growth = True\n","sess   =  tf.compat.v1.Session(config=config)\n","\n","import keras.backend.tensorflow_backend as tf_bkend\n","tf.compat.v1.keras.backend.set_session(sess)\n","\n","from keras import backend as K\n","K.set_image_data_format('channels_last')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x5LUPRTW40mj","colab_type":"text"},"source":["### CNN with 2 CLs and 2 FCs"]},{"cell_type":"code","metadata":{"id":"qURerrsQ40mk","colab_type":"code","colab":{}},"source":["def fer_cnn_model(): \n","\n","    from keras.layers      import Input, Dense, Flatten, Conv2D, MaxPool2D, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, optimizers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","    from keras.layers.normalization import BatchNormalization\n","    import keras.initializers as init\n","    \n","    nb_classes = 7\n","    \n","    inp    = Input(shape = Xtrain[0].shape, name=\"input\" )\n","    #----------------------\n","    conv1  = Conv2D(filters = 16, kernel_size = (2, 2), strides=(1, 1),\n","                    name=\"conv1\", padding=\"same\", activation = 'relu')(inp)\n","    norm1  = BatchNormalization(name=\"bn1\")(conv1)\n","    #----------------------\n","    conv2  = Conv2D(filters = 16, kernel_size = (2, 2), strides=(1, 1),\n","                    name=\"conv2\", padding=\"same\", activation = 'relu')(norm1)\n","    norm2  = BatchNormalization(name=\"bn2\")(conv2)\n","    #----------------------\n","    pool2  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp1\")(norm2)\n","    #----------------------              \n","    flat   = Flatten(name=\"flat\")(pool2)\n","    #----------------------    \n","    dense1 = Dense(128, activation='relu', name=\"dense1_128\")(flat)\n","    drop1  = Dropout(0.30, name=\"dp0.3\" )(dense1)    \n","    #----------------------    \n","    dense2 = Dense(64, activation='relu', name=\"dense2_64\")(drop1)\n","    drop2  = Dropout(0.20, name=\"dp0.2\" )(dense2)        \n","    #----------------------\n","    out    = Dense(nb_classes, activation='softmax', name=\"output\" )(drop2)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","\n","    # model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'] )\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta(lr = 1.0,\n","                                                  rho = 0.95,\n","                                                  epsilon = 1e-08,\n","                                                  decay = 0.0),\n","                  metrics = ['accuracy'] )\n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pgck3zX-40mm","colab_type":"code","colab":{}},"source":["Xtrain[0].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MG94f5IY40mo","colab_type":"text"},"source":["###  CNN with 5 CLs and 2 FCs"]},{"cell_type":"code","metadata":{"id":"zwk8ANNb40mo","colab_type":"code","colab":{}},"source":["def fer_cnn_model2():\n","    \n","    from keras.layers      import Input, Dense, Conv2D, MaxPool2D, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, optimizers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","    \n","    from keras.layers.normalization import BatchNormalization\n","        \n","    import keras.initializers as init\n","    \n","    nb_classes = 7\n","    \n","    inp    = Input( shape = Xtrain[0].shape, name=\"input\" )\n","    #inp    = Input( shape=(0,2304), name=\"input\" )\n","    #----------------------\n","    conv1  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv1\", padding=\"same\", activation = 'relu')(inp)\n","    norm1  = BatchNormalization(name=\"bn1\")(conv1)\n","    #----------------------\n","    conv2  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv2\", padding=\"same\", activation = 'relu')(norm1)\n","    norm2  = BatchNormalization(name=\"bn2\")(conv2)\n","    #----------------------\n","    pool2  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp1\")(norm2)\n","    #----------------------\n","    conv3  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv3\", padding=\"same\", activation = 'relu')(pool2)\n","    norm3  = BatchNormalization(name=\"bn3\")(conv3)\n","    conv4  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv4\", padding=\"same\", activation = 'relu')(norm3)\n","    norm4  = BatchNormalization(name=\"bn4\")(conv4)\n","    conv5  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv5\", padding=\"same\", activation = 'relu')(norm4)\n","    norm5  = BatchNormalization(name=\"bn5\")(conv5)\n","    #----------------------\n","    pool6  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp2\")(norm5)\n","    #----------------------              \n","    flat   = Flatten(name=\"flat\")(pool6)\n","    norm7  = BatchNormalization(name=\"bn7\")(flat)\n","    #----------------------    \n","    dense1 = Dense(1024, activation='relu', name=\"dense1_1024\")(norm7)\n","    drop1  = Dropout(0.30, name=\"dp0.3\")(dense1)    \n","    #----------------------    \n","    dense2 = Dense(512, activation='relu', name=\"dense2_512\")(drop1)\n","    drop2  = Dropout(0.20, name=\"dp0.2\")(dense2)        \n","    #----------------------\n","    out    = Dense(nb_classes, activation='softmax', name=\"output\" )(drop2)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta(lr = 1.0,\n","                                                  rho = 0.95,\n","                                                  epsilon = 1e-08,\n","                                                  decay = 0.0),\n","                  metrics = ['accuracy'] )\n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IRAmRC7FPwSY","colab_type":"text"},"source":["### CNN with 7 CLs and 2 FCs \n","\n"]},{"cell_type":"code","metadata":{"id":"LIzZkPJPPzEf","colab_type":"code","colab":{}},"source":["def fer_cnn_model4():\n","    from keras.layers      import Input, Dense, Conv2D, MaxPool2D, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","    import keras.optimizers as optimizers \n","    \n","    from keras.layers.normalization import BatchNormalization\n","        \n","    import keras.initializers as init\n","    \n","    nb_classes = 7\n","    \n","    inp    = Input( shape = Xtrain[0].shape, name=\"input\" )\n","    #inp    = Input( shape=(0,2304), name=\"input\" )\n","    #----------------------\n","    conv1  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv1\", padding=\"same\", activation = 'relu')(inp)\n","    norm1  = BatchNormalization(name=\"bn1\")(conv1)\n","    #----------------------\n","    conv2  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv2\", padding=\"same\", activation = 'relu')(norm1)\n","    norm2  = BatchNormalization(name=\"bn2\")(conv2)\n","    #----------------------\n","    pool2  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp1\")(norm2)\n","    #----------------------\n","    conv3  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv3\", padding=\"same\", activation = 'relu')(pool2)\n","    norm3  = BatchNormalization(name=\"bn3\")(conv3)\n","    conv4  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv4\", padding=\"same\", activation = 'relu')(norm3)\n","    norm4  = BatchNormalization(name=\"bn4\")(conv4)\n","    conv5  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv5\", padding=\"same\", activation = 'relu')(norm4)\n","    norm5  = BatchNormalization(name=\"bn5\")(conv5)\n","    #----------------------\n","    pool6  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp2\")(norm5)\n","    #----------------------              \n","    conv6  = Conv2D(filters = 256, kernel_size = (3, 3), strides=(1, 1), name=\"conv6\", padding=\"same\", activation = 'relu')(pool6)\n","    norm6  = BatchNormalization(name=\"bn6\")(conv6)\n","    conv7  = Conv2D(filters = 256, kernel_size = (3, 3), strides=(1, 1), name=\"conv7\", padding=\"same\", activation = 'relu')(norm6)\n","    norm7  = BatchNormalization(name=\"bn7\")(conv7)\n","    #----------------------\n","    pool7 =  MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp3\")(norm7)\n","    #----------------------\n","    flat   = Flatten(name=\"flat\")(pool7)\n","    norm8  = BatchNormalization(name=\"bn8\")(flat)\n","    #----------------------    \n","    dense1 = Dense(1024, activation='relu', name=\"dense1_1024\")(norm8)\n","    drop1  = Dropout(0.30, name=\"dp0.3\")(dense1)    \n","    #----------------------    \n","    dense2 = Dense(512, activation='relu', name=\"dense2_512\")(drop1)\n","    drop2  = Dropout(0.20, name=\"dp0.2\")(dense2)        \n","    #----------------------\n","    out    = Dense(nb_classes, activation='softmax', name=\"output\" )(drop2)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta(lr = 1.0,\n","                                                  rho = 0.95,\n","                                                  epsilon = 1e-08,\n","                                                  decay = 0.0),\n","                  metrics = ['acc'] )\n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DbazlMJVP22r","colab_type":"text"},"source":["#### CNN with 3 CLs and 2 FCs"]},{"cell_type":"code","metadata":{"id":"RIpQ6nxFP5lS","colab_type":"code","colab":{}},"source":["def fer_cnn_model3():\n","    \n","    from keras.layers      import Input, Dense, Conv2D, MaxPool2D, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","    import keras.optimizers as optimizers \n","    \n","    from keras.layers.normalization import BatchNormalization\n","        \n","    import keras.initializers as init\n","    \n","    nb_classes = 7\n","    \n","    inp    = Input( shape = Xtrain[0].shape, name=\"input\" )\n","    #inp    = Input( shape=(0,2304), name=\"input\" )\n","    #----------------------\n","    conv1  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv1\", padding=\"same\", activation = 'relu')(inp)\n","    norm1  = BatchNormalization(name=\"bn1\")(conv1)\n","    #----------------------\n","    conv2  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv2\", padding=\"same\", activation = 'relu')(norm1)\n","    norm2  = BatchNormalization(name=\"bn2\")(conv2)\n","    #----------------------\n","    pool2  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp1\")(norm2)\n","    #----------------------\n","    conv3  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv3\", padding=\"same\", activation = 'relu')(pool2)\n","    norm3  = BatchNormalization(name=\"bn3\")(conv3)\n","    conv4  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv4\", padding=\"same\", activation = 'relu')(norm3)\n","    norm4  = BatchNormalization(name=\"bn4\")(conv4)\n","    #----------------------\n","    pool6  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp2\")(norm4)\n","    #----------------------              \n","    flat   = Flatten(name=\"flat\")(pool6)\n","    norm7  = BatchNormalization(name=\"bn7\")(flat)\n","    #----------------------    \n","    dense1 = Dense(1024, activation='relu', name=\"dense1_1024\")(norm7)\n","    drop1  = Dropout(0.40, name=\"dp0.4\")(dense1)    \n","    #----------------------    \n","    dense2 = Dense(512, activation='relu', name=\"dense2_512\")(drop1)\n","    drop2  = Dropout(0.20, name=\"dp0.2\")(dense2)        \n","    #----------------------\n","    out    = Dense(nb_classes, activation='softmax', name=\"output\" )(drop2)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta(lr = 1.0,\n","                                                  rho = 0.95,\n","                                                  epsilon = 1e-08,\n","                                                  decay = 0.0),\n","                  metrics = ['accuracy'] )\n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-ojRmy440mp","colab_type":"text"},"source":["### Build model "]},{"cell_type":"code","metadata":{"id":"rAR8wo9iQCbs","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.callbacks import ModelCheckpoint\n","from livelossplot    import PlotLossesKeras\n","from tensorflow.python.keras           import optimizers\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZpeOIcm1QOcU","colab_type":"text"},"source":["Choose which model to train"]},{"cell_type":"code","metadata":{"id":"vF_yOdtUQGk1","colab_type":"code","colab":{}},"source":["model = fer_cnn_model()\n","str1 = \"weights_FER_CNN_2CL_128_64\" \n","\n","# model = fer_cnn_model2()\n","# str1 = \"weights_FER_CNN_5CL_1028_512\"\n","\n","# model = fer_cnn_model3()\n","# str1 = \"weights_FER_CNN_3CL\"\n","\n","# model = fer_cnn_model4()\n","# str1 = \"weights_FER_CNN_7CL\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDKpmRKo40mq","colab_type":"code","colab":{}},"source":["\n","str2 = \".best.hdf5\"\n","\n","filepath = str1+str2 \n","\n","print(filepath)\n","\n","# setting Early Stop\n","early_stop = EarlyStopping(monitor='val_loss',\n","                              patience=18)\n","\n","checkpoint_acc = ModelCheckpoint( filepath, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max' ) \n","\n","checkpoint_loss = ModelCheckpoint( filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'min' ) \n","\n","callbacks_list = [checkpoint_acc, PlotLossesKeras(), early_stop]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HKfKldRP40mt","colab_type":"text"},"source":["### Train Model"]},{"cell_type":"markdown","metadata":{"id":"Qc2L8Frf40mt","colab_type":"text"},"source":["Without Data Augmentation"]},{"cell_type":"code","metadata":{"id":"_SETCjaM40mu","colab_type":"code","colab":{}},"source":["hist        = []\n","nb_epoch    = 100\n","batch_size  = 80\n","train_steps = Xtrain.shape[0]//batch_size \n","val_steps   = Xval.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model.fit(Xtrain, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = callbacks_list,\n","                      validation_data = (Xval, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q-6dpvdm40mv","colab_type":"text"},"source":["With Data Augmentation"]},{"cell_type":"code","metadata":{"id":"TSw7M_Zf40mw","colab_type":"code","colab":{}},"source":["# Data Generator\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size  = 80\n","\n","train_gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08,\n","                               shear_range=0.3, height_shift_range=0.08,\n","                               zoom_range=0.08)\n","\n","train_generator = train_gen.flow( Xtrain, ytrain, batch_size = batch_size )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NZr6UP840mx","colab_type":"code","colab":{}},"source":["hist        = []\n","nb_epoch    = 500\n","train_steps = Xtrain.shape[0]//batch_size \n","val_steps   = Xval.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model.fit_generator( train_generator,\n","                                epochs = nb_epoch,\n","                                steps_per_epoch = train_steps,\n","                                verbose = 1,\n","                                shuffle = True,\n","                                callbacks = callbacks_list,\n","                                validation_data = (Xval, yval)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzbtCw5n40my","colab_type":"text"},"source":["Evaluate the best model"]},{"cell_type":"code","metadata":{"id":"vFTzZ6BIQZJS","colab_type":"code","colab":{}},"source":["model = fer_cnn_model()\n","# model = fer_cnn_model2()\n","# model = fer_cnn_model3()\n","# model = fer_cnn_model4()\n","\n","# Re-generating the model \n","model.load_weights(filepath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HPkXT7F40mz","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores_tra = model.evaluate(Xtrain, ytrain, verbose = 0)\n","scores_val = model.evaluate(Xval, yval, verbose = 0)\n","scores_tst = model.evaluate(Xtest, ytest, verbose = 0)\n","print(\"FER CNN accuracy on training set  : %.2f%%\" % (scores_tra[1]*100))\n","print(\"FER CNN accuracy on validation set: %.2f%%\" % (scores_val[1]*100))\n","print(\"FER CNN accuracy on test set      : %.2f%%\" % (scores_tst[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_9fYgZW2KOhS"},"source":["### Partie (3a): Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"id":"F_UB7eJzQo-R","colab_type":"text"},"source":["#### Vos résultats ici:\n","\n","##### Model1 :\n","\n","| Ensemble | Taux de classification correct |                               \n","|----------|--------------------------------|\n","| App      | 96.3  %                        |                   \n","| Val      | 50.13 %                        |                             \n","| Test     | 50.68 %                        | \n","\n","#####  Model1 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 66.75  %                         |                   \n"," | Val      | 54.81 %                        |                             \n"," | Test     | 56.20 %                         | \n","\n","#####  Model2 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 96.3  %                         |                   \n"," | Val      | 50.13 %                        |                             \n"," | Test     | 50.68 %                         |  \n","\n","#####  Model2 - Data Augmentation\n","\n","| Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 89.10 %                        |                   \n"," | Val      | 67.7 %                         |                             \n"," | Test     | 68.3%                          |  \n","\n","#####  Model3 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.75%                         |                   \n"," | Val      | 58.62%                         |                             \n"," | Test     | 59.85%                         |  \n","\n","#####  Model3 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 80.64%                         |                   \n"," | Val      | 62.64%                         |                             \n"," | Test     | 63.61%                         |  \n","\n","\n","##### Model1 :\n","\n","| Ensemble | Taux de classification correct |                               \n","|----------|--------------------------------|\n","| App      | 96.3  %                        |                   \n","| Val      | 50.13 %                        |                             \n","| Test     | 50.68 %                        | \n","\n","#####  Model1 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 66.75  %                         |                   \n"," | Val      | 54.81 %                        |                             \n"," | Test     | 56.20 %                         | \n","\n","#####  Model2 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 96.3  %                         |                   \n"," | Val      | 50.13 %                        |                             \n"," | Test     | 50.68 %                         |  \n","\n","#####  Model2 - Data Augmentation\n","\n","| Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 89.10 %                        |                   \n"," | Val      | 67.7 %                         |                             \n"," | Test     | 68.3%                          |  \n","\n","#####  Model3 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.75%                         |                   \n"," | Val      | 58.62%                         |                             \n"," | Test     | 59.85%                         |  \n","\n","#####  Model3 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 80.64%                         |                   \n"," | Val      | 62.64%                         |                             \n"," | Test     | 63.61%                         |   \n","\n","           \n","#####  Model4 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.32%                         |                   \n"," | Val      | 62.36%                         |                             \n"," | Test     | 63.11%                         |   \n","\n","           \n","#####  Model4 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 98.8%                          |                   \n"," | Val      | 67.93%                         |                             \n"," | Test     | 68.63%                         |   \n"," "]},{"cell_type":"markdown","metadata":{"id":"uLL7m_hxxXzj","colab_type":"text"},"source":["### Analyse\n"]},{"cell_type":"markdown","metadata":{"id":"yIv1Jhd8x2Ro","colab_type":"text"},"source":["Les modèles 1 et 2 ont été faits par l’enseignant et les modèles 3 et 4 ont été faits par l’équipe 10. Chaque modèle suit cette configuration, des couches de convolutions segmentées avec des couches de pooling, ensuite deux couches entièrement connectées avec un certain drop-out pour éviter le surapprentissage. Finalement, ils utilisent l’activation relu pour la couche dense et l’activation soft-max pour la couche sortie. \n","\n","De plus, pour éviter de faire des itérations inutiles, nous surveillons la perte (calculé par une fonction categorial_crossentropy) et dès qu’il n’y a pas de diminution de perte pour 18 itérations, nous arrêtons l’apprentissage (c à dire du early stopping) et nous sauvegardons les poids avec la meilleure précision. La valeur 18 a été trouvée expérimentalement et selon nos entrainements, elle permet d’arrêter notre modèle lorsqu’on est certain que ce dernier ne peut plus s’améliorer.    \n","\n","Le modèle trois contient trois couches de convolutions : deux ont 64 filtres et la dernière couche a 128 filtres. En augmentant le modèle une couche additionnelle, elle performe mieux que le modèle 1 simple, soit 56.20% (modèle 1) versus 63.63% (modèle 2) sur les données augmentées.  Nous avons haussé le drop-out rate de 10% pour de la première couche entièrement connectée. Cela est pour essayer d’éviter le surapprentissage.  Si nous la comparons avec notre modèle 4, qui contient sept couches convolutives, la différence de précision sur les données tests est de 5%; le modèle 4 est plus précis. \n","\n"," Le modèle quatre contient sept couches : deux avec 64 filtres, trois avec 128 filtres et deux avec 256 filtres.  Notre équipe a remarqué que le modèle 2 performait mieux que le modèle 1, alors en augmentant les couches de convolution ainsi que les filtres, nous avons espéré avoir de meilleurs résultats.  Cependant, ce n’est pas nécessairement le cas. En effet, le taux de classification de l’ensemble augmenté test est de 68.3% et 68.63% pour le modèle 2 et le modèle 4 respectivement. Il n’est pas possible de finir que l’un soit meilleur à classifier nos données FER, car la différence peut être attribuée à des facteurs externes, tels la chance ou notre early stopping. Comparé au modèle 2, le modèle 4 est en surentrainement avec un taux de classification de 98%.  Nous utilisons déjà les drop-outs, batch normalisation, l’augmentation des données et l’early stopping, mais après l’entrainement, le modèle est toujours en surapprentissage. Dans notre cas, simplement augmenter le nombre de couches et ,en ce faisant, augmenter la complexité du modèle n’aide pas à la classification. Faute de temps et manque de matérielle, nous n’avons pas pu tester d’autres modèles. On note que le modèle 4 souffre de surapprentissage. Pour améliorer cela, nous avions pu ajouter des drop-outs plus agressifs et ajouter une autre couche entièrement connectée.\n","\n","#### Data Augmentation\n","Selon la théorie apprise en cours, l’augmentation de données est utile pour éviter le sur-apprentissage. Comme il possible de voir dans chacun des modèles sans augmentation, leur taux de classification correct est toujours 95%+ pour les données app. Et à cause de cet sur-apprentissage, le taux de classification de l’ensemble test en souffre. Cependant, lorsque les modèles sont entrainés avec des ensembles augmentés, leur taux de classification de l’ensemble app diminue, mais leur taux de classification test augmente. Ces valeurs sont comparées aux taux sans augmentation. Prenons l’exemple du modèle 3, sans augmentation, le taux de l’ensemble app est de 99.32% et le taux de l’ensemble test est de 59.85%. Après l’augmentation, le taux de l’ensemble app est de 80.64% (environ 19% plus bas) et le taux de classification pour l’ensemble test est de 63.61%, soit une augmentation d’environ 4%. Les modèles 1 et 2 suivent cette tendance. Pour le modèle 4, l’entrainement avec l’augmentation des données baisse de précision d’environ 1% dans l’ensemble app pour augmenter d’environ 5% dans l’ensemble test avec l’ensemble augmenté. Le modèle performe techniquement mieux lorsque ce dernier est entrainé avec l’ensemble augmenté. Cependant, on note qu’il est toujours en sur-apprentissage (98%).    "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FqpTfG-RRSZp"},"source":["<font color=black>\n","    \n","### Partie (3b): Code CNN Pré-entraîné (FER):\n","\n","##### À faire:\n","1. Récupérer une des architectures CNN pré-entraînes disponibles dans Keras pour faire un \"transfert de connaissance (transfer learning). Faire un \"fine-tuning\" du modèle choisi sur FER.    \n","2. Entraîner et optimiser les paramètres du réseau.\n","3. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n","\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"wY9VajdGC4Vp","colab_type":"text"},"source":["### Load VGG16"]},{"cell_type":"code","metadata":{"id":"ho658FAlDCPv","colab_type":"code","colab":{}},"source":["from keras import models\n","from keras import layers\n","from keras import optimizers, initializers\n","from keras.models import Model\n","from keras.layers import Lambda, Input, Concatenate, Flatten, Dense, Dropout\n","from keras.preprocessing import image\n","from keras.applications import VGG16\n","\n","nb_classes = 7\n","\n","# Input image size for VGG16\n","#image_size = 224  \n","image_size = 48  \n","\n","inp       = Input( shape = Xtrain[0].shape, name=\"input\" )\n","img_conc  = Concatenate(name=\"3channels\")( [inp, inp, inp] )\n","\n","vgg_model = VGG16( weights='imagenet', include_top = False, input_shape = (image_size, image_size, 3) )\n","\n","# let's visualize layer names and layer indices to see how many layers\n","# we should freeze:\n","for i, layer in enumerate(vgg_model.layers):\n","     print(i, layer.name)\n","\n","# We chose to train the 2 last CLs, i.e. we will freeze\n","# the first layers and unfreeze the rest.\n","# Freeze the layers except the last 2 layers\n","for layer in vgg_model.layers[:-2]:\n","    layer.trainable = False\n","\n","# Check the trainable status of the individual layers\n","for layer in vgg_model.layers:\n","    print(layer, layer.trainable)\n","\n","# Add new layers\n","flat   = Flatten(name=\"flat\")(vgg_model(img_conc))\n","dense1 = Dense(128, activation='relu', kernel_initializer = initializers.glorot_uniform( seed = 0), name=\"dense_128\")(flat)\n","drop1  = Dropout(0.2, name=\"dp0.2\")(dense1)\n","\n","dense2 = Dense(nb_classes, activation='softmax', name=\"output\")(drop1)\n","\n","model  = Model(inp, dense2)\n"," \n","# Show a summary of the model. Check the number of trainable parameters\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHzvYqhDDIHW","colab_type":"text"},"source":["### Build the model"]},{"cell_type":"code","metadata":{"id":"FBpqP-uUDF_p","colab_type":"code","colab":{}},"source":["model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = optimizers.Adadelta( lr = 1.0, rho = 0.95, epsilon = 1e-08, decay = 0.0),\n","                  metrics = ['accuracy'] )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vUpCYaI1DL55","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","from livelossplot    import PlotLossesKeras\n","from keras           import optimizers\n","\n","#checkpoints\n","str1 = \"weights_FER_VGG16_128\" \n","str2 = \".best.hdf5\"\n","\n","filepath = str1+str2 \n","\n","print(filepath)\n","\n","checkpoint = ModelCheckpoint( filepath, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max' ) \n","\n","callbacks_list = [ checkpoint, PlotLossesKeras() ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LdJMvDmpDOPF","colab_type":"text"},"source":["### Train the model without data augmentation"]},{"cell_type":"code","metadata":{"id":"lGLvHzgMCjBz","colab_type":"code","colab":{}},"source":["hist        = []\n","nb_epoch    = 100\n","batch_size  = 100\n","train_steps = Xtrain.shape[0]//batch_size \n","val_steps   = Xval.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model.fit(Xtrain, ytrain,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = callbacks_list,\n","                      validation_data = (Xval, yval)\n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8bqi4XhDr3H","colab_type":"text"},"source":["### Train the model without data augmentation"]},{"cell_type":"code","metadata":{"id":"3HP5N8F-DtwZ","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size  = 100\n","\n","train_gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08,\n","                               shear_range=0.3, height_shift_range=0.08,\n","                               zoom_range=0.08)\n","\n","train_generator = train_gen.flow( Xtrain, ytrain, batch_size = batch_size )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cynayzdMDvtY","colab_type":"code","colab":{}},"source":["hist        = []\n","nb_epoch    = 300\n","train_steps = Xtrain.shape[0]//batch_size \n","val_steps   = Xval.shape[0]//batch_size \n","\n","hist.append(model.fit_generator( train_generator,\n","                                epochs = nb_epoch,\n","                                steps_per_epoch = train_steps,\n","                                verbose = 1,\n","                                shuffle = True,\n","                                callbacks = callbacks_list,\n","                                validation_data = (Xval, yval)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUgB99eBDzu5","colab_type":"text"},"source":["### Evaluate the best model"]},{"cell_type":"code","metadata":{"id":"Uy_exzPbD1lg","colab_type":"code","colab":{}},"source":["# Re-generating the model \n","# Charger le modele approprié \n","model.load_weights(\"weights_FER_VGG16_128.best.hdf5\")\n","\n","# Final evaluation of the model\n","scores_tra = model.evaluate(Xtrain, ytrain, verbose = 0)\n","scores_val = model.evaluate(Xval, yval, verbose = 0)\n","scores_tst = model.evaluate(Xtest, ytest, verbose = 0)\n","print(\"FER CNN accuracy on training set  : %.2f%%\" % (scores_tra[1]*100))\n","print(\"FER CNN accuracy on validation set: %.2f%%\" % (scores_val[1]*100))\n","print(\"FER CNN accuracy on test set      : %.2f%%\" % (scores_tst[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JaK9aoTLRb3h"},"source":["### Partie (3b): Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DOCSXxu1RWp5"},"source":["\n","| Ensemble | Model 4  | VGG19 CNN           | VGG19 unAug CNN |\n","|----------|----------|---------------------|-----------------|\n","| App      | 98.48%   |     88.93%          |      99.49%     |\n","| Val      | 67.93%   |     53.83%          |      54.58%     |            \n","| Test     | 68.63%   |     56.14%          |      56.14%     |    \n"]},{"cell_type":"markdown","metadata":{"id":"tlow_Ckfx8hq","colab_type":"text"},"source":["### Analyse\n"]},{"cell_type":"markdown","metadata":{"id":"InIbsH3Lx-3c","colab_type":"text"},"source":["Dans cette partie, nous avons simplement utilisé le code du professeur sur le VGG19, faute de ne plus avoir accès au local de GPU.  En le comparant avec notre modèle 4, nous remarquons que notre modèle performe mieux que VGG19 de 16 % sur l’ensemble test. VGG19 est un modèle très complexe avec 13 couches convolutives. Ce dernier a été entrainé sur des milliers de classe d’objets et d’animaux, mais pas spécifiquement sur des visages humains. Nous le comparons à notre modèle 4 qui a été entrainé exclusivement sur des visages. Après l’entrainement, VGG19 peut classifier un peu plus de la moitié des classes. Cela est environs 13% plus bas que notre modèle 4. Cela est peut être dû au fait que notre modèle 4 a été exclusivement optimisé pour detecter non seulement des visages, mais les visages de FER.  Dans tous les cas, le modèle 4 est clairement supérieur à classifier l’ensemble FER et il nous donne les meilleurs résultats de tous les modèles testés à date. De plus, encore une autre fois, il est clair qu’en utilisant des données augmentées, nous notons qu’on évite la surapprentissage à une certaine mesure, soit 88.93% au lieu de 99.49%. Cependant, cela ne traduit pas à une meilleure précision dans l’ensemble test."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KIQmuheSRfYw"},"source":["<font color=magenta>\n","\n","### Partie (3c): Code CNN Pré-entraîné (FG-NET):\n","\n","##### À faire:\n","1. Choisir le modèle \\ l’architecture qu’a donné de meilleurs résultats sur FER pour faire un “transfert de connaissance (transfer learning).\n","2. Adapter ce modèle pour FG-NET (couche de sortie classification (7 unités) -> régression (1 unité)).   \n","3. Entraîner (\"fine-tuning\" du modèle choisi sur FG-NET) et optimiser les paramètres du réseau pour la régression.\n","4. Évaluer la pertinence d’utiliser \"data augmentation\" pour améliorer la généralisation.\n","5. Faire une analyse des résultats et présenter vos conclusions sur les réseaux de neurones.\n","    \n","</font>"]},{"cell_type":"markdown","metadata":{"id":"3seqWQo4RY7-","colab_type":"text"},"source":["### Load and transform FG-NET data if not already done\n"]},{"cell_type":"code","metadata":{"id":"ALjsjWZVRbtD","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import math\n","import numpy\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjGDLQMwR74q","colab_type":"code","colab":{}},"source":["X_data = np.loadtxt('fgnet/fgnet_48x48.csv', delimiter=',', dtype=int)\n","Y_data = np.loadtxt('fgnet/fgnet_labels.csv', delimiter=',', dtype=int)\n","Y_subj = np.loadtxt('fgnet/fgnet_subjects.csv', delimiter=',', dtype=int)\n","\n","# normalize\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","X_data = scaler.fit_transform(X_data)\n","\n","# reshape to be [samples][pixels][width][height]\n","X_data = X_data.reshape(X_data.shape[0], 48, 48, 1).astype('float32')\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Training set\n","X_train, X_valtest, Y_train, Y_valtest = train_test_split(X_data,\n","                                                          Y_data,\n","                                                          test_size = 0.50,\n","                                                          random_state = 7)\n","X_data.shape, X_train.shape, X_valtest.shape\n","\n","# Validation and Test Sets\n","X_val, X_test, Y_val, Y_test = train_test_split(X_valtest,\n","                                                Y_valtest,\n","                                                test_size = 0.60,\n","                                                random_state = 7)\n","X_train.shape, X_val.shape, X_test.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_LRdih4SCKv","colab_type":"text"},"source":["###  VGG19 model"]},{"cell_type":"code","metadata":{"id":"lxJGY44BR96J","colab_type":"code","colab":{}},"source":[" def vgg19_reg():\n","    from keras import models\n","    from keras import layers\n","    from keras import optimizers, initializers\n","    from keras.models import Model\n","    from keras.layers import Lambda, Input, Concatenate, Flatten, Dense, Dropout\n","    from keras.preprocessing import image\n","    from keras.applications import VGG16\n","\n","    nb_classes = 7\n","\n","    image_size = 48  \n","\n","    inp       = Input( shape = X_data[0].shape, name=\"input\" )\n","    img_conc  = Concatenate(name=\"3channels\")( [inp, inp, inp] )\n","\n","    # Load the pre-trained modeel, ignoring the fully connected and outputt layers\n","    vgg_model = VGG16( weights='imagenet', include_top = False, input_shape = (image_size, image_size, 3) )\n","\n","    # let's visualize layer names and layer indices to see how many layers\n","    # we should freeze:\n","    for i, layer in enumerate(vgg_model.layers):\n","         print(i, layer.name)\n","\n","    # We chose to train the 2 last CLs, i.e. we will freeze\n","    # the first layers and unfreeze the rest.\n","    # Freeze the layers except the last 4 layers\n","    for layer in vgg_model.layers[:-4]:\n","        layer.trainable = False\n","\n","    # Check the trainable status of the individual layers\n","    for layer in vgg_model.layers:\n","        print(layer, layer.trainable)\n","\n","    # Add new layers\n","    flat   = Flatten(name=\"flat\")(vgg_model(img_conc))\n","    dense1 = Dense(128, activation='relu', kernel_initializer = initializers.glorot_uniform( seed = 0), name=\"dense_128\")(flat)\n","    drop1  = Dropout(0.2, name=\"dp0.2\")(dense1)\n","    # Single output, linear activation\n","    dense2 = Dense(1, activation='linear', name=\"output\")(drop1)\n","\n","    model  = Model(inp, dense2)\n","\n","    # Show a summary of the model. Check the number of trainable parameters\n","    model.summary()\n","    #checkpoints\n","    model.compile(loss = 'mae',\n","                optimizer = optimizers.Adadelta( lr = 1.0, rho = 0.95, epsilon = 1e-08, decay = 0.0),\n","                metrics = ['mae', 'mse'] )\n","\n","    return model "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXkma7rnSHXN","colab_type":"text"},"source":["### Model 4"]},{"cell_type":"code","metadata":{"id":"jv3Q_EiBSNAA","colab_type":"code","colab":{}},"source":["def cnn_model4_reg():\n","\n","    from keras.layers      import Input, Dense, Conv2D, MaxPool2D, Flatten\n","    from keras.layers.core import Dropout\n","    from keras.models      import Model\n","    from keras             import initializers, regularizers\n","    from keras.callbacks   import ModelCheckpoint\n","\n","    from keras           import optimizers\n","\n","    from keras.layers.normalization import BatchNormalization\n","        \n","    import keras.initializers as init\n","        \n","    inp    = Input( shape = X_train[0].shape, name=\"input\" )\n","    #----------------------\n","    conv1  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv1\", padding=\"same\", activation = 'relu')(inp)\n","    norm1  = BatchNormalization(name=\"bn1\")(conv1)\n","    #----------------------\n","    conv2  = Conv2D(filters = 64, kernel_size = (2, 2), strides=(1, 1), name=\"conv2\", padding=\"same\", activation = 'relu')(norm1)\n","    norm2  = BatchNormalization(name=\"bn2\")(conv2)\n","    #----------------------\n","    pool2  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp1\")(norm2)\n","    #----------------------\n","    conv3  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv3\", padding=\"same\", activation = 'relu')(pool2)\n","    norm3  = BatchNormalization(name=\"bn3\")(conv3)\n","    conv4  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv4\", padding=\"same\", activation = 'relu')(norm3)\n","    norm4  = BatchNormalization(name=\"bn4\")(conv4)\n","    conv5  = Conv2D(filters = 128, kernel_size = (3, 3), strides=(1, 1), name=\"conv5\", padding=\"same\", activation = 'relu')(norm4)\n","    norm5  = BatchNormalization(name=\"bn5\")(conv5)\n","    #----------------------\n","    pool6  = MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp2\")(norm5)\n","    #----------------------              \n","    conv6  = Conv2D(filters = 256, kernel_size = (3, 3), strides=(1, 1), name=\"conv6\", padding=\"same\", activation = 'relu')(pool6)\n","    norm6  = BatchNormalization(name=\"bn6\")(conv6)\n","    conv7  = Conv2D(filters = 256, kernel_size = (3, 3), strides=(1, 1), name=\"conv7\", padding=\"same\", activation = 'relu')(norm6)\n","    norm7  = BatchNormalization(name=\"bn7\")(conv7)\n","    #----------------------\n","    pool7 =  MaxPool2D(pool_size = (2, 2), strides = 2, name=\"mp3\")(norm7)\n","    #----------------------\n","    flat   = Flatten(name=\"flat\")(pool7)\n","    norm8  = BatchNormalization(name=\"bn8\")(flat)\n","    #----------------------    \n","    dense1 = Dense(1024, activation='relu', name=\"dense1_1024\")(norm8)\n","    drop1  = Dropout(0.30, name=\"dp0.3\")(dense1)    \n","    #----------------------    \n","    dense2 = Dense(512, activation='relu', name=\"dense2_512\")(drop1)\n","    drop2  = Dropout(0.20, name=\"dp0.2\")(dense2)        \n","    #----------------------\n","    # Single output, linear activation\n","    out    = Dense(1, activation='linear', name=\"output\")(drop2)\n","    #----------------------\n","\n","    model  = Model(inp, out)\n","\n","    model.summary()\n","    \n","    #checkpoints\n","    model.compile(loss = 'mae',\n","                optimizer = optimizers.Adadelta( lr = 1.0, rho = 0.95, epsilon = 1e-08, decay = 0.0),\n","                metrics = ['mae', 'mse'] )\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rd5YzRsPSprC","colab_type":"text"},"source":["Choose model"]},{"cell_type":"code","metadata":{"id":"W8LdKqdSSrl_","colab_type":"code","colab":{}},"source":["str1 = \"weights_FGNET_VGG16_128_1\" \n","model = vgg19_reg()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ku81GY24O6nq","colab_type":"text"},"source":["OR"]},{"cell_type":"code","metadata":{"id":"aw6R0BlESt61","colab_type":"code","colab":{}},"source":["str1 = \"aug_weights_FGNET_CNN_7L\"\n","model = cnn_model4_reg()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEr189wZSwYZ","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","from livelossplot    import PlotLossesKeras\n","\n","\n","str2 = \".best.hdf5\"\n","\n","filepath = str1+str2 \n","\n","print(filepath)\n","\n","checkpoint = ModelCheckpoint( filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'min' ) \n","\n","callbacks_list = [ checkpoint, PlotLossesKeras() ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2imEIbyQSzDZ","colab_type":"text"},"source":["### Train Model"]},{"cell_type":"markdown","metadata":{"id":"gzvzKoLwS4Ej","colab_type":"text"},"source":["Without Data Augmentation"]},{"cell_type":"code","metadata":{"id":"BGGza72nS2TC","colab_type":"code","colab":{}},"source":["hist        = []\n","nb_epoch    = 500\n","batch_size  = 80\n","train_steps = X_train.shape[0]//batch_size \n","val_steps   = X_val.shape[0]//batch_size \n","\n","#fitting the model \n","hist.append(model.fit(X_train, Y_train,\n","                      batch_size = batch_size, \n","                      epochs = nb_epoch,\n","                      verbose = 1,\n","                      shuffle = True,\n","                      callbacks = callbacks_list,\n","                      validation_data = (X_val, Y_val) \n","                     ))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7WX8PqTJS7z1","colab_type":"text"},"source":["Data Augmentation"]},{"cell_type":"code","metadata":{"id":"0WjGb5POS9T-","colab_type":"code","colab":{}},"source":["# Data Generator\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size  = 80\n","\n","train_gen = ImageDataGenerator(rotation_range = 8, width_shift_range = 0.08,\n","                               shear_range = 0.3, height_shift_range = 0.08,\n","                               zoom_range = 0.08)\n","\n","train_generator = train_gen.flow( X_train, Y_train, batch_size = batch_size )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6iAS7-o8S_Vr","colab_type":"code","colab":{}},"source":["\n","hist        = []\n","nb_epoch    = 500\n","train_steps = X_train.shape[0] // batch_size \n","val_steps   = X_val.shape[0] // batch_size \n","\n","#fitting the model \n","hist.append(model.fit( train_generator,\n","                                epochs = nb_epoch,\n","                                steps_per_epoch = train_steps,\n","                                verbose = 1,\n","                                shuffle = True,\n","                                callbacks = callbacks_list,\n","                                validation_data = (X_val, Y_val) ) )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbqbJ8FlTDqJ","colab_type":"text"},"source":["### Evaluate best model for VGG16\n"]},{"cell_type":"code","metadata":{"id":"iw7B692NTHMS","colab_type":"code","colab":{}},"source":["# Re-generating the model \n","model = vgg19_reg()\n","model.load_weights(\"aug_weights_FGNET_VGG16_128_1.best.hdf5\")\n","\n","# Final evaluation of the model\n","scores_tra = model.evaluate(X_train, Y_train, verbose = 0)\n","scores_val = model.evaluate(X_val, Y_val, verbose = 0)\n","scores_tst = model.evaluate(X_test, Y_test, verbose = 0)\n","print(\"FG-NET CNN accuracy on training set  : %.2f MAE\" % (scores_tra[0]))\n","print(\"FG-NET CNN accuracy on validation set: %.2f MAE\" % (scores_val[0]))\n","print(\"FG-NET CNN accuracy on test set      : %.2f MAE\" % (scores_tst[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwzZFt4fTOy5","colab_type":"text"},"source":["### Evaluate best model CNN 7 CL"]},{"cell_type":"code","metadata":{"id":"ciECn074TQrS","colab_type":"code","colab":{}},"source":["# Re-generating the model \n","model = cnn_model4_reg()\n","model.load_weights(\"weights_FGNET_CNN_7L.best.hdf5\")\n","\n","# Final evaluation of the model\n","scores_tra = model.evaluate(X_train, Y_train, verbose = 0)\n","scores_val = model.evaluate(X_val, Y_val, verbose = 0)\n","scores_tst = model.evaluate(X_test, Y_test, verbose = 0)\n","print(\"FG-NET CNN accuracy on training set  : %.2f MAE\" % (scores_tra[0]))\n","print(\"FG-NET CNN accuracy on validation set: %.2f MAE\" % (scores_val[0]))\n","print(\"FG-NET CNN accuracy on test set      : %.2f MAE\" % (scores_tst[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEsfD0OATUQh","colab_type":"code","colab":{}},"source":["# Re-generating the model with AUGMENTED DATA \n","model = cnn_model4_reg()\n","model.load_weights(\"aug_weights_FGNET_CNN_7L.best.hdf5\")\n","\n","# Final evaluation of the model\n","scores_tra = model.evaluate(X_train, Y_train, verbose = 0)\n","scores_val = model.evaluate(X_val, Y_val, verbose = 0)\n","scores_tst = model.evaluate(X_test, Y_test, verbose = 0)\n","print(\"FG-NET CNN accuracy on training set  : %.2f MAE\" % (scores_tra[0]))\n","print(\"FG-NET CNN accuracy on validation set: %.2f MAE\" % (scores_val[0]))\n","print(\"FG-NET CNN accuracy on test set      : %.2f MAE\" % (scores_tst[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TYVAvzNVRnrQ"},"source":["### Partie (3c): Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bmK7Iv78RkHp"},"source":["#### Vos résultats ici:\n","\n","| Ensemble |Model 4   |Model 4 - Aug| VGG19 CNN            | VGG19 UnAug CNN    |                 \n","|----------|------------|-------------|----------------------|--------------------|\n","| App      | 1.99 MAE   |  1.54 MAE                | 0.65 MAE             |    1.21       MAE  | \n","| Val      | 6.66 MAE   |  5.81 MAE                | 6.7  MAE             |    7.07       MAE  |       \n","| Test     | 6.19 MAE   |  5.26 MAE                | 6.75 MAE             |    6.90       MAE  |\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cuSVMYfblGPB","colab_type":"text"},"source":["initialement mal comprise. Cependant, cela nous permet de valider l’efficacité du modèle choisi comparé au VGG19. Avec l’augmentation de données, nous avons une MAE de 5.26 pour notre modèle 4 comparé à 6.75 pour VGG19. Clairement, le modèle 4 est supérieur. Les valeurs de FG-NET varient entre 0 à 69, soit 69 ans. Dans cette mesure, si la prédiction de personne dévie de 5.26 ans depuis la bonne réponse, cela veut dire que l’erreur de la prédiction est relativement bonne pour un modèle qui a été initialement entrainé pour détecter des émotions et non des âges.  Nous pouvons attribuer ce taux favorable au fait que notre modèle 4 a été développé pour extraire et analyser des visages humains. En mentionné dans la section b, cela n’est pas le cas pour le VGG19. D’autre part, nous pouvons remarquer que l’ensemble app augmenté du VGG19 nous donne une erreur moyenne la plus petite, soit 0.65 MAE. On peut dire que le modèle est en surapprentissage, mais grâce à l’augmentation de données, sa MAE sur l’ensemble test est plus petite que celui du modèle non-augmenté. Comme dans tous les autres cas auparavant, l’augmentation de données génère toujours des modèles plus précis lors de la prédiction des ensembles tests, car le modèle fait face à plus d’exemples distinctes qui le permet de faire une meilleure régression.  Cependant, comme on peut le voir ici, elle ne permet pas toujours d’éviter le surapprentissage.  \n","\n","Nous aurions pu aussi utiliser RMSE qui pénalise beaucoup plus les grandes erreurs. On a gardé MSE, car ne savant pas quels genres d’erreurs que nous allions avoir et considérant les valeurs possibles, soit 0 à 69, il ne semble pas nécessaire d’utiliser RMSE.   \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xcLIleDUKOha"},"source":["## Partie Final: Conclusion"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Fh5G8vFHKOhb"},"source":["<font color=magenta>\n","\n","##### À faire:\n","1. Résumer et comparer les principaux résultats obtenus pour la classification (FER) et régression (FG-NET).\n","2. Faire une analyse des résultats obtenus et présenter vos conclusions sur les différents modèles que vous avez entraînés (classification et régression).\n","3. Comparer les résultats obtenus sur FER avec les résultats du laboratoire 1 (vecteur de pixels, vecteur de primitives, vecteur de primitives + PCA). Avez-vous observé une amélioration? Commenter sur les temps d'apprentissage, complexité spatiale et temporelle, etc.\n","    \n","</font>"]},{"cell_type":"markdown","metadata":{"id":"9coEgMAo6Swe","colab_type":"text"},"source":["Voici les résultats obtenus pour l'algorithme de régression avec (FG-NET dataset) ainsi que pour les algorithmes de classification (FER dataset) dans la partie 1 du laboratoire.\n","\n","|  Primitive   | Noyau    |   Paramètres       |  MAE   |  MSE   | Comparaison | Primitive   | Noyau       |   Paramètres    |  % App | % Val  | % Tst  | \n","|--------------|----------|--------------------||--------|--------|--------------|-------------|-----------------|--------|--------|--------|\n","| FG_NET |  Lin     | C=100,ep=2               |8.286   |  144.864       |----| LBP avec PCA | lineaire    | C=256            | 19.123 | 18.501 | 19.170       |\n","||||||----| LBP avec PCA | polynomial  | C=10,d=6         |  17.311 |16.968        | 17.414       |\n","||||||----| LBP avec PCA | RBF         | C=256, g=0.01   | 18.865 | 18.807 | 17.414 |\n","||||||----| CNN 5L 2FC     | lineaire    | C=10            | 25.37 | 16.912 |  17.024      |\n","||||||----| CNN 5L 2FC     | polynomial  | C=10,d=3         |  76.683 | 14.712       |  16.299      |\n","||||||----| CNN 5L 2FC     | RBF         | C=10,d=3,g=0.05   | 91.946 |16.188 | 18.278     |\n","\n","Pour ce qui est de la partie 1 avec la régression sur les données FG-NET, les principaux résultats qu'on peut observer sont avec la régression SVR avec un noyau linéaire dont la MSE obtenue est de 144.864 et MAE obtenue est de 8.286. Puis, pour la partie avec la classification sur les données FER, avec les primitives LBP avec transformation PCA, les principaux résultats avec le modèle SVM sont avec une précision entre 17% et 19% avec les noyaux linéaire, polynomial et rbf et ceux avec les vecteurs de primitives CNN sont proche avec une précision entre 15% et 18%, toutefois l'erreur reste assez élevée pour les modèles. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3P5YiPNmKOhc"},"source":["### Partie Final: Résultats et résponses:"]},{"cell_type":"markdown","metadata":{"id":"ZMIlbhj3U10w","colab_type":"text"},"source":["Voici les résultats obtenus pour les algorithmes de régression (FG-NET dataset)\n","ainsi que pour les algorithmes de classification (FER dataset) dans la partie 1 et la partie 2 du laboratoire. \n","\n","\n","| Algorithme Régression           | Paramètres                |  MSE  |  MAE  || Algorithme Classification      | Paramètres    | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n","|-----------------------|---------------------------|-------|-------|-|------------------|---------------|-----------|-------------|-------------|-------------|\n","| Regr lineaire         | aucun                     |179.22 | 11.56 || Regr logistique  | V1-FER        |   0.36  |   51    |   64    |   64    |\n","| Regr Ridge            | alpha = 100               |44.20  | 6.09  || Regr logistique  | V2-SIFT       |   0.25    |   74        |   75    |   75    |\n","| Regr Lasso            | alpha = 0.05              | 46.30 | 6.16  || Regr logistique  | V2-LBP        |   0.27  |   73    |   74    |   73    |\n","| Regr ElasticNet       | alpha = 0.05, l1_ratio=0.5| 47.35 | 6.26  || Regr logistique  | V3-PCA-SIFT   |   0.24 |    75    |   75    |   76    |\n","|                       |                           |       |       ||Regr logistique  | V3-PCA_LBP    |   0.24  |   75    |   75    |   76    |\n","|                       |                           |       |       ||Regr logistique  | V3-F-SIFT     |   0.25  |    74    |   75    |   75    |\n","|                       |                           |       |       ||Regr logistique  | V3-F-LBP      |   0.27  |    74    |   73    |   73    |\n","\n","Pour ce qui est de la partie 1 avec la régression sur les données FG-NET, les principaux résultats qu'on peut observer sont avec la régression Ridge dont la MSE est de 44.20 et MAE de 6.09 suivis de celle avec Lasso dont le MSE est de 46.30 et MAE de 6.16 puis celle avec ElasticNet avec le MSE de 47.35 et MAE de 6.26. Seule la régression linéaire ordinaire n'est pas aussi proche. \n","\n","Pour ce qui est de la partie 2 avec la classification sur les données FER, les principaux résultats avec la régression logistique sont avec les primitives sur les pixels avec une précision de 36% et les autres modèles entrainés ont une précision de moins de 27%.\n","\n","Pour la partie de classification à l'aide de réseaux perceptron multicouches avec les données FER ci-dessous, les principaux résultats sont avec les primitives sur les pixels avec une précision de 29.09% et les primitives LBP PCA avec une précision de moins de 24.49%. Pour les autres, leurs résultats moins élevés avec une précision de 17.86% jusqu'à 13.18%.\n","\n","| Algorithme classification      | Paramètres    | Precision | %Erreur App | %Erreur Val | %Erreur Tst | \n","|------------------|---------------|-----------|-------------|-------------|-------------|\n","| MLP FER      | 0:1180160:2048:65664:0:903        |   29.09  |   70.42    |   69.74    |   70.91    |\n","| MLP SIFT     | 0:66048:2048:65664:0:903 |   14.57  |   86.00    |   87.02    |   85.43    |\n","| MLP LBP      | 0:13824:2048:65664:0:903        |   13.18  |   83.67    |   83.76    |   86.82    |\n","| MLP F SIFT   | 0:1536:2048:65664:0:903       |   17.86  |   84.53    |   82.25    |   82.14    |\n","| MLP F LBP    | 0:25088:2048:65664:0:903         |   14.71  |   85.74    |   86.15    |   85.29    |\n","| MLP PCA SIFT | 0:1536:2048:65664:0:903        |   13.43  |   88.87    |   84.90    |   86.47    |\n","| MLP PCA LBP  | 0:13824:2048:65664:0:903         |   24.49  |   74.89    |   75.06    |   75.51    |"]},{"cell_type":"markdown","metadata":{"id":"yh_PG233lV6g","colab_type":"text"},"source":["### Partie 3 Conclusion"]},{"cell_type":"markdown","metadata":{"id":"HiqiQJaflatV","colab_type":"text"},"source":["FER"]},{"cell_type":"markdown","metadata":{"id":"dTDRLl83loKu","colab_type":"text"},"source":["\n","\n","##### Model1 :\n","\n","| Ensemble | Taux de classification correct |                               \n","|----------|--------------------------------|\n","| App      | 96.3  %                        |                   \n","| Val      | 50.13 %                        |                             \n","| Test     | 50.68 %                        | \n","\n","#####  Model1 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 66.75  %                         |                   \n"," | Val      | 54.81 %                        |                             \n"," | Test     | 56.20 %                         | \n","\n","#####  Model2 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 96.3  %                         |                   \n"," | Val      | 50.13 %                        |                             \n"," | Test     | 50.68 %                         |  \n","\n","#####  Model2 - Data Augmentation\n","\n","| Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 89.10 %                        |                   \n"," | Val      | 67.7 %                         |                             \n"," | Test     | 68.3%                          |  \n","\n","#####  Model3 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.75%                         |                   \n"," | Val      | 58.62%                         |                             \n"," | Test     | 59.85%                         |  \n","\n","#####  Model3 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 80.64%                         |                   \n"," | Val      | 62.64%                         |                             \n"," | Test     | 63.61%                         |  \n","\n","\n","##### Model1 :\n","\n","| Ensemble | Taux de classification correct |                               \n","|----------|--------------------------------|\n","| App      | 96.3  %                        |                   \n","| Val      | 50.13 %                        |                             \n","| Test     | 50.68 %                        | \n","\n","#####  Model1 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 66.75  %                         |                   \n"," | Val      | 54.81 %                        |                             \n"," | Test     | 56.20 %                         | \n","\n","#####  Model2 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 96.3  %                         |                   \n"," | Val      | 50.13 %                        |                             \n"," | Test     | 50.68 %                         |  \n","\n","#####  Model2 - Data Augmentation\n","\n","| Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 89.10 %                        |                   \n"," | Val      | 67.7 %                         |                             \n"," | Test     | 68.3%                          |  \n","\n","#####  Model3 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.75%                         |                   \n"," | Val      | 58.62%                         |                             \n"," | Test     | 59.85%                         |  \n","\n","#####  Model3 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 80.64%                         |                   \n"," | Val      | 62.64%                         |                             \n"," | Test     | 63.61%                         |   \n","\n","           \n","#####  Model4 \n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 99.32%                         |                   \n"," | Val      | 62.36%                         |                             \n"," | Test     | 63.11%                         |   \n","\n","           \n","#####  Model4 - Data Augmentation\n","\n"," | Ensemble | Taux de classification correct |                               \n"," |----------|--------------------------------|\n"," | App      | 98.8%                          |                   \n"," | Val      | 67.93%                         |                             \n"," | Test     | 68.63%                         |   \n"," "]},{"cell_type":"markdown","metadata":{"id":"oE_la2NxlMqC","colab_type":"text"},"source":["\n","| Ensemble | Model 4  | VGG19 CNN           | VGG19 unAug CNN |\n","|----------|----------|---------------------|-----------------|\n","| App      | 98.48%   |     88.93%          |      99.49%     |\n","| Val      | 67.93%   |     53.83%          |      54.58%     |            \n","| Test     | 68.63%   |     56.14%          |      56.14%     |    "]},{"cell_type":"markdown","metadata":{"id":"rHvA4bKWlftO","colab_type":"text"},"source":["FG-NET"]},{"cell_type":"markdown","metadata":{"id":"aY7y66KZlb_z","colab_type":"text"},"source":["\n","| Ensemble |Model 4   |Model 4 - Aug| VGG19 CNN            | VGG19 UnAug CNN    |                 \n","|----------|------------|-------------|----------------------|--------------------|\n","| App      | 1.99 MAE   |  1.54 MAE                | 0.65 MAE             |    1.21       MAE  | \n","| Val      | 6.66 MAE   |  5.81 MAE                | 6.7  MAE             |    7.07       MAE  |       \n","| Test     | 6.19 MAE   |  5.26 MAE                | 6.75 MAE             |    6.90       MAE  |\n"]},{"cell_type":"markdown","metadata":{"id":"qePM3UxIl_5A","colab_type":"text"},"source":["De tous les modèles analysés à date dans le laboratoire 2, les CNNs sont clairement supérieurs pour l’analyse d’images. Avec n’importe quel modèle (1,2,3,4 ou VGG19), nous pouvons garantir qu’au moins la moitié des exemples vont être correctement classifié. Cela n’est pas le cas pour notre MLP ou le meilleur résultat a une précision  de 29%.  \n","\n","Au lieu de trouver les meilleures primitives à analyser comme nous l’avions fait dans le laboratoire précédent, nous laissons notre CNN s’occuper des facteurs discriminants dans chaque image. Le plus grand désavantage de travailler avec des CNNs est le matériel nécessaire pour effectuer l’entrainement. En effet, dans le laboratoire de GTI771, nous pouvons utiliser des TITAN X qui sont des GPUs de plusieurs centaines de dollars. Avec un 1060 3 GB, un entrainement de 20 minutes sur un TITAN a pris plusieurs heures.  Un autre problème des CNNs, comme nous avons discuté plus haut, est le fait qu’il faut toujours contrer le surapprentissage en faisant des drop-outs, des données augmentées, etc.\n","\n","La meilleure précision trouvée dans le laboratoire 1 est de 32% avec un KNN ayant un K de 30 et en utilisant le grid search simple avec les données FER. Notre CNN le bat de très loin, même si le temps d’entrainement est plus long (un KNN n’a quasiment pas de temps d’entrainement) pour ce dernier. De plus, lorsque nos modèles du laboratoire 1 ont été face aux données Jaffe 256x256, ils n’étaient pas mieux que l’aléatoire. Même si notre CNN modèle 4 n’a pas été testée sur l’ensemble Jaffe, il est clair selon ses résultats mentionnés plus haut, qu’il serait capable de mieux les classifier.       "]}]}